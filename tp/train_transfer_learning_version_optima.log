time python train_transfer_learning_exp8.py
2019-03-25 19:15:14.535892: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-25 19:15:14.541266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-03-25 19:15:14.663660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-25 19:15:14.691232: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x5f597b0 executing computations on platform CUDA. Devices:
2019-03-25 19:15:14.691257: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce RTX 2060, Compute Capability 7.5
2019-03-25 19:15:14.713146: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-03-25 19:15:14.713510: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x5fc6140 executing computations on platform Host. Devices:
2019-03-25 19:15:14.713529: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>
2019-03-25 19:15:14.713797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: GeForce RTX 2060 major: 7 minor: 5 memoryClockRate(GHz): 1.83
pciBusID: 0000:01:00.0
totalMemory: 5.76GiB freeMemory: 5.31GiB
2019-03-25 19:15:14.713826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-25 19:15:14.713879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-03-25 19:15:14.714534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-25 19:15:14.714546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-25 19:15:14.714553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-25 19:15:14.714687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5136 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-03-25 19:15:14.724186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-25 19:15:14.724227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-25 19:15:14.724235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-25 19:15:14.724241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-25 19:15:14.724360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5136 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5
9412608/9406464 [==============================] - 19s 2us/step
optimizer=SGD(lr=0.01, momentum=0.9)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
Conv1_pad_1 (ZeroPadding2D)     (None, 129, 129, 3)  0           input_2[0][0]                    
__________________________________________________________________________________________________
Conv1_pad_2 (ZeroPadding2D)     (None, 129, 129, 3)  0           input_4[0][0]                    
__________________________________________________________________________________________________
Conv1_1 (Conv2D)                (None, 64, 64, 32)   864         Conv1_pad_1[0][0]                
__________________________________________________________________________________________________
Conv1_2 (Conv2D)                (None, 64, 64, 32)   864         Conv1_pad_2[0][0]                
__________________________________________________________________________________________________
bn_Conv1_1 (BatchNormalizationV (None, 64, 64, 32)   128         Conv1_1[0][0]                    
__________________________________________________________________________________________________
bn_Conv1_2 (BatchNormalizationV (None, 64, 64, 32)   128         Conv1_2[0][0]                    
__________________________________________________________________________________________________
Conv1_relu_1 (ReLU)             (None, 64, 64, 32)   0           bn_Conv1_1[0][0]                 
__________________________________________________________________________________________________
Conv1_relu_2 (ReLU)             (None, 64, 64, 32)   0           bn_Conv1_2[0][0]                 
__________________________________________________________________________________________________
expanded_conv_depthwise_1 (Dept (None, 64, 64, 32)   288         Conv1_relu_1[0][0]               
__________________________________________________________________________________________________
expanded_conv_depthwise_2 (Dept (None, 64, 64, 32)   288         Conv1_relu_2[0][0]               
__________________________________________________________________________________________________
expanded_conv_depthwise_BN_1 (B (None, 64, 64, 32)   128         expanded_conv_depthwise_1[0][0]  
__________________________________________________________________________________________________
expanded_conv_depthwise_BN_2 (B (None, 64, 64, 32)   128         expanded_conv_depthwise_2[0][0]  
__________________________________________________________________________________________________
expanded_conv_depthwise_relu_1  (None, 64, 64, 32)   0           expanded_conv_depthwise_BN_1[0][0
__________________________________________________________________________________________________
expanded_conv_depthwise_relu_2  (None, 64, 64, 32)   0           expanded_conv_depthwise_BN_2[0][0
__________________________________________________________________________________________________
expanded_conv_project_1 (Conv2D (None, 64, 64, 16)   512         expanded_conv_depthwise_relu_1[0]
__________________________________________________________________________________________________
expanded_conv_project_2 (Conv2D (None, 64, 64, 16)   512         expanded_conv_depthwise_relu_2[0]
__________________________________________________________________________________________________
expanded_conv_project_BN_1 (Bat (None, 64, 64, 16)   64          expanded_conv_project_1[0][0]    
__________________________________________________________________________________________________
expanded_conv_project_BN_2 (Bat (None, 64, 64, 16)   64          expanded_conv_project_2[0][0]    
__________________________________________________________________________________________________
block_1_expand_1 (Conv2D)       (None, 64, 64, 96)   1536        expanded_conv_project_BN_1[0][0] 
__________________________________________________________________________________________________
block_1_expand_2 (Conv2D)       (None, 64, 64, 96)   1536        expanded_conv_project_BN_2[0][0] 
__________________________________________________________________________________________________
block_1_expand_BN_1 (BatchNorma (None, 64, 64, 96)   384         block_1_expand_1[0][0]           
__________________________________________________________________________________________________
block_1_expand_BN_2 (BatchNorma (None, 64, 64, 96)   384         block_1_expand_2[0][0]           
__________________________________________________________________________________________________
block_1_expand_relu_1 (ReLU)    (None, 64, 64, 96)   0           block_1_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_1_expand_relu_2 (ReLU)    (None, 64, 64, 96)   0           block_1_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_1_pad_1 (ZeroPadding2D)   (None, 65, 65, 96)   0           block_1_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_1_pad_2 (ZeroPadding2D)   (None, 65, 65, 96)   0           block_1_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_1_depthwise_1 (DepthwiseC (None, 32, 32, 96)   864         block_1_pad_1[0][0]              
__________________________________________________________________________________________________
block_1_depthwise_2 (DepthwiseC (None, 32, 32, 96)   864         block_1_pad_2[0][0]              
__________________________________________________________________________________________________
block_1_depthwise_BN_1 (BatchNo (None, 32, 32, 96)   384         block_1_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_1_depthwise_BN_2 (BatchNo (None, 32, 32, 96)   384         block_1_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_1_depthwise_relu_1 (ReLU) (None, 32, 32, 96)   0           block_1_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_1_depthwise_relu_2 (ReLU) (None, 32, 32, 96)   0           block_1_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_1_project_1 (Conv2D)      (None, 32, 32, 24)   2304        block_1_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_1_project_2 (Conv2D)      (None, 32, 32, 24)   2304        block_1_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_1_project_BN_1 (BatchNorm (None, 32, 32, 24)   96          block_1_project_1[0][0]          
__________________________________________________________________________________________________
block_1_project_BN_2 (BatchNorm (None, 32, 32, 24)   96          block_1_project_2[0][0]          
__________________________________________________________________________________________________
block_2_expand_1 (Conv2D)       (None, 32, 32, 144)  3456        block_1_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_2_expand_2 (Conv2D)       (None, 32, 32, 144)  3456        block_1_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_2_expand_BN_1 (BatchNorma (None, 32, 32, 144)  576         block_2_expand_1[0][0]           
__________________________________________________________________________________________________
block_2_expand_BN_2 (BatchNorma (None, 32, 32, 144)  576         block_2_expand_2[0][0]           
__________________________________________________________________________________________________
block_2_expand_relu_1 (ReLU)    (None, 32, 32, 144)  0           block_2_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_2_expand_relu_2 (ReLU)    (None, 32, 32, 144)  0           block_2_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_1 (DepthwiseC (None, 32, 32, 144)  1296        block_2_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_2_depthwise_2 (DepthwiseC (None, 32, 32, 144)  1296        block_2_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_2_depthwise_BN_1 (BatchNo (None, 32, 32, 144)  576         block_2_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_BN_2 (BatchNo (None, 32, 32, 144)  576         block_2_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_relu_1 (ReLU) (None, 32, 32, 144)  0           block_2_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_2_depthwise_relu_2 (ReLU) (None, 32, 32, 144)  0           block_2_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_2_project_1 (Conv2D)      (None, 32, 32, 24)   3456        block_2_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_2_project_2 (Conv2D)      (None, 32, 32, 24)   3456        block_2_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_2_project_BN_1 (BatchNorm (None, 32, 32, 24)   96          block_2_project_1[0][0]          
__________________________________________________________________________________________________
block_2_project_BN_2 (BatchNorm (None, 32, 32, 24)   96          block_2_project_2[0][0]          
__________________________________________________________________________________________________
block_2_add_1 (Add)             (None, 32, 32, 24)   0           block_1_project_BN_1[0][0]       
                                                                 block_2_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_2_add_2 (Add)             (None, 32, 32, 24)   0           block_1_project_BN_2[0][0]       
                                                                 block_2_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_3_expand_1 (Conv2D)       (None, 32, 32, 144)  3456        block_2_add_1[0][0]              
__________________________________________________________________________________________________
block_3_expand_2 (Conv2D)       (None, 32, 32, 144)  3456        block_2_add_2[0][0]              
__________________________________________________________________________________________________
block_3_expand_BN_1 (BatchNorma (None, 32, 32, 144)  576         block_3_expand_1[0][0]           
__________________________________________________________________________________________________
block_3_expand_BN_2 (BatchNorma (None, 32, 32, 144)  576         block_3_expand_2[0][0]           
__________________________________________________________________________________________________
block_3_expand_relu_1 (ReLU)    (None, 32, 32, 144)  0           block_3_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_3_expand_relu_2 (ReLU)    (None, 32, 32, 144)  0           block_3_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_3_pad_1 (ZeroPadding2D)   (None, 33, 33, 144)  0           block_3_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_3_pad_2 (ZeroPadding2D)   (None, 33, 33, 144)  0           block_3_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_3_depthwise_1 (DepthwiseC (None, 16, 16, 144)  1296        block_3_pad_1[0][0]              
__________________________________________________________________________________________________
block_3_depthwise_2 (DepthwiseC (None, 16, 16, 144)  1296        block_3_pad_2[0][0]              
__________________________________________________________________________________________________
block_3_depthwise_BN_1 (BatchNo (None, 16, 16, 144)  576         block_3_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_3_depthwise_BN_2 (BatchNo (None, 16, 16, 144)  576         block_3_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_3_depthwise_relu_1 (ReLU) (None, 16, 16, 144)  0           block_3_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_3_depthwise_relu_2 (ReLU) (None, 16, 16, 144)  0           block_3_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_3_project_1 (Conv2D)      (None, 16, 16, 32)   4608        block_3_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_3_project_2 (Conv2D)      (None, 16, 16, 32)   4608        block_3_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_3_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_3_project_1[0][0]          
__________________________________________________________________________________________________
block_3_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_3_project_2[0][0]          
__________________________________________________________________________________________________
block_4_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_3_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_4_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_3_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_4_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_4_expand_1[0][0]           
__________________________________________________________________________________________________
block_4_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_4_expand_2[0][0]           
__________________________________________________________________________________________________
block_4_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_4_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_4_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_4_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_1 (DepthwiseC (None, 16, 16, 192)  1728        block_4_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_4_depthwise_2 (DepthwiseC (None, 16, 16, 192)  1728        block_4_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_4_depthwise_BN_1 (BatchNo (None, 16, 16, 192)  768         block_4_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_BN_2 (BatchNo (None, 16, 16, 192)  768         block_4_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_relu_1 (ReLU) (None, 16, 16, 192)  0           block_4_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_4_depthwise_relu_2 (ReLU) (None, 16, 16, 192)  0           block_4_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_4_project_1 (Conv2D)      (None, 16, 16, 32)   6144        block_4_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_4_project_2 (Conv2D)      (None, 16, 16, 32)   6144        block_4_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_4_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_4_project_1[0][0]          
__________________________________________________________________________________________________
block_4_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_4_project_2[0][0]          
__________________________________________________________________________________________________
block_4_add_1 (Add)             (None, 16, 16, 32)   0           block_3_project_BN_1[0][0]       
                                                                 block_4_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_4_add_2 (Add)             (None, 16, 16, 32)   0           block_3_project_BN_2[0][0]       
                                                                 block_4_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_5_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_4_add_1[0][0]              
__________________________________________________________________________________________________
block_5_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_4_add_2[0][0]              
__________________________________________________________________________________________________
block_5_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_5_expand_1[0][0]           
__________________________________________________________________________________________________
block_5_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_5_expand_2[0][0]           
__________________________________________________________________________________________________
block_5_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_5_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_5_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_5_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_1 (DepthwiseC (None, 16, 16, 192)  1728        block_5_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_5_depthwise_2 (DepthwiseC (None, 16, 16, 192)  1728        block_5_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_5_depthwise_BN_1 (BatchNo (None, 16, 16, 192)  768         block_5_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_BN_2 (BatchNo (None, 16, 16, 192)  768         block_5_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_relu_1 (ReLU) (None, 16, 16, 192)  0           block_5_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_5_depthwise_relu_2 (ReLU) (None, 16, 16, 192)  0           block_5_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_5_project_1 (Conv2D)      (None, 16, 16, 32)   6144        block_5_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_5_project_2 (Conv2D)      (None, 16, 16, 32)   6144        block_5_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_5_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_5_project_1[0][0]          
__________________________________________________________________________________________________
block_5_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_5_project_2[0][0]          
__________________________________________________________________________________________________
block_5_add_1 (Add)             (None, 16, 16, 32)   0           block_4_add_1[0][0]              
                                                                 block_5_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_5_add_2 (Add)             (None, 16, 16, 32)   0           block_4_add_2[0][0]              
                                                                 block_5_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_6_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_5_add_1[0][0]              
__________________________________________________________________________________________________
block_6_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_5_add_2[0][0]              
__________________________________________________________________________________________________
block_6_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_6_expand_1[0][0]           
__________________________________________________________________________________________________
block_6_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_6_expand_2[0][0]           
__________________________________________________________________________________________________
block_6_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_6_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_6_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_6_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_6_pad_1 (ZeroPadding2D)   (None, 17, 17, 192)  0           block_6_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_6_pad_2 (ZeroPadding2D)   (None, 17, 17, 192)  0           block_6_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_6_depthwise_1 (DepthwiseC (None, 8, 8, 192)    1728        block_6_pad_1[0][0]              
__________________________________________________________________________________________________
block_6_depthwise_2 (DepthwiseC (None, 8, 8, 192)    1728        block_6_pad_2[0][0]              
__________________________________________________________________________________________________
block_6_depthwise_BN_1 (BatchNo (None, 8, 8, 192)    768         block_6_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_6_depthwise_BN_2 (BatchNo (None, 8, 8, 192)    768         block_6_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_6_depthwise_relu_1 (ReLU) (None, 8, 8, 192)    0           block_6_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_6_depthwise_relu_2 (ReLU) (None, 8, 8, 192)    0           block_6_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_6_project_1 (Conv2D)      (None, 8, 8, 64)     12288       block_6_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_6_project_2 (Conv2D)      (None, 8, 8, 64)     12288       block_6_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_6_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_6_project_1[0][0]          
__________________________________________________________________________________________________
block_6_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_6_project_2[0][0]          
__________________________________________________________________________________________________
block_7_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_6_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_7_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_6_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_7_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_7_expand_1[0][0]           
__________________________________________________________________________________________________
block_7_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_7_expand_2[0][0]           
__________________________________________________________________________________________________
block_7_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_7_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_7_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_7_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_7_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_7_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_7_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_7_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_7_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_7_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_7_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_7_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_7_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_7_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_7_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_7_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_7_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_7_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_7_project_1[0][0]          
__________________________________________________________________________________________________
block_7_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_7_project_2[0][0]          
__________________________________________________________________________________________________
block_7_add_1 (Add)             (None, 8, 8, 64)     0           block_6_project_BN_1[0][0]       
                                                                 block_7_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_7_add_2 (Add)             (None, 8, 8, 64)     0           block_6_project_BN_2[0][0]       
                                                                 block_7_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_8_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_7_add_1[0][0]              
__________________________________________________________________________________________________
block_8_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_7_add_2[0][0]              
__________________________________________________________________________________________________
block_8_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_8_expand_1[0][0]           
__________________________________________________________________________________________________
block_8_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_8_expand_2[0][0]           
__________________________________________________________________________________________________
block_8_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_8_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_8_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_8_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_8_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_8_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_8_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_8_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_8_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_8_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_8_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_8_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_8_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_8_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_8_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_8_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_8_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_8_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_8_project_1[0][0]          
__________________________________________________________________________________________________
block_8_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_8_project_2[0][0]          
__________________________________________________________________________________________________
block_8_add_1 (Add)             (None, 8, 8, 64)     0           block_7_add_1[0][0]              
                                                                 block_8_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_8_add_2 (Add)             (None, 8, 8, 64)     0           block_7_add_2[0][0]              
                                                                 block_8_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_9_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_8_add_1[0][0]              
__________________________________________________________________________________________________
block_9_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_8_add_2[0][0]              
__________________________________________________________________________________________________
block_9_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_9_expand_1[0][0]           
__________________________________________________________________________________________________
block_9_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_9_expand_2[0][0]           
__________________________________________________________________________________________________
block_9_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_9_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_9_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_9_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_9_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_9_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_9_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_9_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_9_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_9_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_9_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_9_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_9_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_9_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_9_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_9_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_9_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_9_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_9_project_1[0][0]          
__________________________________________________________________________________________________
block_9_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_9_project_2[0][0]          
__________________________________________________________________________________________________
block_9_add_1 (Add)             (None, 8, 8, 64)     0           block_8_add_1[0][0]              
                                                                 block_9_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_9_add_2 (Add)             (None, 8, 8, 64)     0           block_8_add_2[0][0]              
                                                                 block_9_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_10_expand_1 (Conv2D)      (None, 8, 8, 384)    24576       block_9_add_1[0][0]              
__________________________________________________________________________________________________
block_10_expand_2 (Conv2D)      (None, 8, 8, 384)    24576       block_9_add_2[0][0]              
__________________________________________________________________________________________________
block_10_expand_BN_1 (BatchNorm (None, 8, 8, 384)    1536        block_10_expand_1[0][0]          
__________________________________________________________________________________________________
block_10_expand_BN_2 (BatchNorm (None, 8, 8, 384)    1536        block_10_expand_2[0][0]          
__________________________________________________________________________________________________
block_10_expand_relu_1 (ReLU)   (None, 8, 8, 384)    0           block_10_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_10_expand_relu_2 (ReLU)   (None, 8, 8, 384)    0           block_10_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_1 (Depthwise (None, 8, 8, 384)    3456        block_10_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_10_depthwise_2 (Depthwise (None, 8, 8, 384)    3456        block_10_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_10_depthwise_BN_1 (BatchN (None, 8, 8, 384)    1536        block_10_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_BN_2 (BatchN (None, 8, 8, 384)    1536        block_10_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_relu_1 (ReLU (None, 8, 8, 384)    0           block_10_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_10_depthwise_relu_2 (ReLU (None, 8, 8, 384)    0           block_10_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_10_project_1 (Conv2D)     (None, 8, 8, 96)     36864       block_10_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_10_project_2 (Conv2D)     (None, 8, 8, 96)     36864       block_10_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_10_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_10_project_1[0][0]         
__________________________________________________________________________________________________
block_10_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_10_project_2[0][0]         
__________________________________________________________________________________________________
block_11_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_10_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_11_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_10_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_11_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_11_expand_1[0][0]          
__________________________________________________________________________________________________
block_11_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_11_expand_2[0][0]          
__________________________________________________________________________________________________
block_11_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_11_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_11_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_11_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_1 (Depthwise (None, 8, 8, 576)    5184        block_11_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_11_depthwise_2 (Depthwise (None, 8, 8, 576)    5184        block_11_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_11_depthwise_BN_1 (BatchN (None, 8, 8, 576)    2304        block_11_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_BN_2 (BatchN (None, 8, 8, 576)    2304        block_11_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_relu_1 (ReLU (None, 8, 8, 576)    0           block_11_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_11_depthwise_relu_2 (ReLU (None, 8, 8, 576)    0           block_11_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_11_project_1 (Conv2D)     (None, 8, 8, 96)     55296       block_11_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_11_project_2 (Conv2D)     (None, 8, 8, 96)     55296       block_11_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_11_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_11_project_1[0][0]         
__________________________________________________________________________________________________
block_11_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_11_project_2[0][0]         
__________________________________________________________________________________________________
block_11_add_1 (Add)            (None, 8, 8, 96)     0           block_10_project_BN_1[0][0]      
                                                                 block_11_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_11_add_2 (Add)            (None, 8, 8, 96)     0           block_10_project_BN_2[0][0]      
                                                                 block_11_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_12_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_11_add_1[0][0]             
__________________________________________________________________________________________________
block_12_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_11_add_2[0][0]             
__________________________________________________________________________________________________
block_12_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_12_expand_1[0][0]          
__________________________________________________________________________________________________
block_12_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_12_expand_2[0][0]          
__________________________________________________________________________________________________
block_12_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_12_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_12_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_12_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_1 (Depthwise (None, 8, 8, 576)    5184        block_12_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_12_depthwise_2 (Depthwise (None, 8, 8, 576)    5184        block_12_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_12_depthwise_BN_1 (BatchN (None, 8, 8, 576)    2304        block_12_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_BN_2 (BatchN (None, 8, 8, 576)    2304        block_12_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_relu_1 (ReLU (None, 8, 8, 576)    0           block_12_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_12_depthwise_relu_2 (ReLU (None, 8, 8, 576)    0           block_12_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_12_project_1 (Conv2D)     (None, 8, 8, 96)     55296       block_12_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_12_project_2 (Conv2D)     (None, 8, 8, 96)     55296       block_12_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_12_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_12_project_1[0][0]         
__________________________________________________________________________________________________
block_12_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_12_project_2[0][0]         
__________________________________________________________________________________________________
block_12_add_1 (Add)            (None, 8, 8, 96)     0           block_11_add_1[0][0]             
                                                                 block_12_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_12_add_2 (Add)            (None, 8, 8, 96)     0           block_11_add_2[0][0]             
                                                                 block_12_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_13_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_12_add_1[0][0]             
__________________________________________________________________________________________________
block_13_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_12_add_2[0][0]             
__________________________________________________________________________________________________
block_13_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_13_expand_1[0][0]          
__________________________________________________________________________________________________
block_13_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_13_expand_2[0][0]          
__________________________________________________________________________________________________
block_13_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_13_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_13_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_13_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_13_pad_1 (ZeroPadding2D)  (None, 9, 9, 576)    0           block_13_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_13_pad_2 (ZeroPadding2D)  (None, 9, 9, 576)    0           block_13_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_13_depthwise_1 (Depthwise (None, 4, 4, 576)    5184        block_13_pad_1[0][0]             
__________________________________________________________________________________________________
block_13_depthwise_2 (Depthwise (None, 4, 4, 576)    5184        block_13_pad_2[0][0]             
__________________________________________________________________________________________________
block_13_depthwise_BN_1 (BatchN (None, 4, 4, 576)    2304        block_13_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_13_depthwise_BN_2 (BatchN (None, 4, 4, 576)    2304        block_13_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_13_depthwise_relu_1 (ReLU (None, 4, 4, 576)    0           block_13_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_13_depthwise_relu_2 (ReLU (None, 4, 4, 576)    0           block_13_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_13_project_1 (Conv2D)     (None, 4, 4, 160)    92160       block_13_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_13_project_2 (Conv2D)     (None, 4, 4, 160)    92160       block_13_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_13_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_13_project_1[0][0]         
__________________________________________________________________________________________________
block_13_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_13_project_2[0][0]         
__________________________________________________________________________________________________
block_14_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_13_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_14_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_13_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_14_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_14_expand_1[0][0]          
__________________________________________________________________________________________________
block_14_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_14_expand_2[0][0]          
__________________________________________________________________________________________________
block_14_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_14_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_14_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_14_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_14_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_14_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_14_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_14_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_14_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_14_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_14_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_14_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_14_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_14_project_1 (Conv2D)     (None, 4, 4, 160)    153600      block_14_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_14_project_2 (Conv2D)     (None, 4, 4, 160)    153600      block_14_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_14_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_14_project_1[0][0]         
__________________________________________________________________________________________________
block_14_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_14_project_2[0][0]         
__________________________________________________________________________________________________
block_14_add_1 (Add)            (None, 4, 4, 160)    0           block_13_project_BN_1[0][0]      
                                                                 block_14_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_14_add_2 (Add)            (None, 4, 4, 160)    0           block_13_project_BN_2[0][0]      
                                                                 block_14_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_15_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_14_add_1[0][0]             
__________________________________________________________________________________________________
block_15_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_14_add_2[0][0]             
__________________________________________________________________________________________________
block_15_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_15_expand_1[0][0]          
__________________________________________________________________________________________________
block_15_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_15_expand_2[0][0]          
__________________________________________________________________________________________________
block_15_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_15_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_15_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_15_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_15_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_15_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_15_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_15_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_15_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_15_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_15_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_15_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_15_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_15_project_1 (Conv2D)     (None, 4, 4, 160)    153600      block_15_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_15_project_2 (Conv2D)     (None, 4, 4, 160)    153600      block_15_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_15_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_15_project_1[0][0]         
__________________________________________________________________________________________________
block_15_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_15_project_2[0][0]         
__________________________________________________________________________________________________
block_15_add_1 (Add)            (None, 4, 4, 160)    0           block_14_add_1[0][0]             
                                                                 block_15_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_15_add_2 (Add)            (None, 4, 4, 160)    0           block_14_add_2[0][0]             
                                                                 block_15_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_16_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_15_add_1[0][0]             
__________________________________________________________________________________________________
block_16_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_15_add_2[0][0]             
__________________________________________________________________________________________________
block_16_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_16_expand_1[0][0]          
__________________________________________________________________________________________________
block_16_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_16_expand_2[0][0]          
__________________________________________________________________________________________________
block_16_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_16_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_16_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_16_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_16_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_16_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_16_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_16_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_16_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_16_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_16_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_16_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_16_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_16_project_1 (Conv2D)     (None, 4, 4, 320)    307200      block_16_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_16_project_2 (Conv2D)     (None, 4, 4, 320)    307200      block_16_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_16_project_BN_1 (BatchNor (None, 4, 4, 320)    1280        block_16_project_1[0][0]         
__________________________________________________________________________________________________
block_16_project_BN_2 (BatchNor (None, 4, 4, 320)    1280        block_16_project_2[0][0]         
__________________________________________________________________________________________________
Conv_1_1 (Conv2D)               (None, 4, 4, 1280)   409600      block_16_project_BN_1[0][0]      
__________________________________________________________________________________________________
Conv_1_2 (Conv2D)               (None, 4, 4, 1280)   409600      block_16_project_BN_2[0][0]      
__________________________________________________________________________________________________
Conv_1_bn_1 (BatchNormalization (None, 4, 4, 1280)   5120        Conv_1_1[0][0]                   
__________________________________________________________________________________________________
Conv_1_bn_2 (BatchNormalization (None, 4, 4, 1280)   5120        Conv_1_2[0][0]                   
__________________________________________________________________________________________________
out_relu_1 (ReLU)               (None, 4, 4, 1280)   0           Conv_1_bn_1[0][0]                
__________________________________________________________________________________________________
out_relu_2 (ReLU)               (None, 4, 4, 1280)   0           Conv_1_bn_2[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 20480)        0           out_relu_1[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 20480)        0           out_relu_2[0][0]                 
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40960)        0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
fc1 (Dense)                     (None, 1024)         41944064    concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           fc1[0][0]                        
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 8)            8200        dropout[0][0]                    
==================================================================================================
Total params: 46,468,232
Trainable params: 44,676,104
Non-trainable params: 1,792,128
__________________________________________________________________________________________________
None
------------- Training -------------
40670
8134
epochs: 196
epochs per stage: 49
Epoch 1/196
2019-03-25 19:16:05.968504: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-03-25 19:16:06.251163: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-03-25 19:16:07.706576: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profile Session started.
2019-03-25 19:16:07.771386: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcupti.so.10.0
   1/1016 [..............................] - ETA: 7:10:49 - loss: 23.1647 - mse: 6.4187 - mace: 101.8564WARNING: Logging before flag parsing goes to stderr.
W0325 19:16:08.315948 140619320846080 callbacks.py:236] Method (on_train_batch_end) is slow compared to the batch update (0.252277). Check your callbacks.
   2/1016 [..............................] - ETA: 3:37:07 - loss: 23.6607 - mse: 8.7153 - mace: 117.8462W0325 19:16:08.385679 140619320846080 callbacks.py:236] Method (on_train_batch_end) is slow compared to the batch update (0.122486). Check your callbacks.
1015/1016 [============================>.] - ETA: 0s - loss: 5.8645 - mse: 0.3592 - mace: 24.0888       
Epoch 00001: val_loss improved from inf to 1.16888, saving model to checkpoint.h5
1016/1016 [==============================] - 145s 142ms/step - loss: 5.8599 - mse: 0.3591 - mace: 24.0878 - val_loss: 1.1689 - val_mse: 0.3619 - val_mace: 24.6561
Epoch 2/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.8284 - mse: 0.2726 - mace: 21.5361  
Epoch 00002: val_loss improved from 1.16888 to 0.94493, saving model to checkpoint.h5
1016/1016 [==============================] - 120s 118ms/step - loss: 0.8282 - mse: 0.2725 - mace: 21.5350 - val_loss: 0.9449 - val_mse: 0.4610 - val_mace: 27.5932
Epoch 3/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6922 - mse: 0.2353 - mace: 19.8396  
Epoch 00003: val_loss did not improve from 0.94493
1016/1016 [==============================] - 116s 114ms/step - loss: 0.6922 - mse: 0.2353 - mace: 19.8390 - val_loss: 1.1700 - val_mse: 0.7327 - val_mace: 35.4393
Epoch 4/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6557 - mse: 0.2206 - mace: 19.1699  
Epoch 00004: val_loss did not improve from 0.94493
1016/1016 [==============================] - 121s 119ms/step - loss: 0.6556 - mse: 0.2205 - mace: 19.1681 - val_loss: 1.0625 - val_mse: 0.6096 - val_mace: 32.3504
Epoch 5/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6345 - mse: 0.2134 - mace: 18.7962  
Epoch 00005: val_loss did not improve from 0.94493
1016/1016 [==============================] - 116s 114ms/step - loss: 0.6345 - mse: 0.2134 - mace: 18.7961 - val_loss: 1.0041 - val_mse: 0.5531 - val_mace: 30.7559
Epoch 6/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6230 - mse: 0.2091 - mace: 18.5945  
Epoch 00006: val_loss improved from 0.94493 to 0.79497, saving model to checkpoint.h5
1016/1016 [==============================] - 120s 118ms/step - loss: 0.6231 - mse: 0.2091 - mace: 18.5946 - val_loss: 0.7950 - val_mse: 0.3512 - val_mace: 24.1501
Epoch 7/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6163 - mse: 0.2063 - mace: 18.4643  
Epoch 00007: val_loss improved from 0.79497 to 0.77708, saving model to checkpoint.h5
1016/1016 [==============================] - 121s 119ms/step - loss: 0.6164 - mse: 0.2063 - mace: 18.4649 - val_loss: 0.7771 - val_mse: 0.3380 - val_mace: 23.6515
Epoch 8/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6107 - mse: 0.2038 - mace: 18.3289  
Epoch 00008: val_loss did not improve from 0.77708
1016/1016 [==============================] - 117s 115ms/step - loss: 0.6108 - mse: 0.2038 - mace: 18.3293 - val_loss: 0.8651 - val_mse: 0.4194 - val_mace: 26.4597
Epoch 9/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6068 - mse: 0.2007 - mace: 18.2047  
Epoch 00009: val_loss did not improve from 0.77708
1016/1016 [==============================] - 117s 115ms/step - loss: 0.6068 - mse: 0.2007 - mace: 18.2055 - val_loss: 0.8232 - val_mse: 0.3826 - val_mace: 25.1490
Epoch 10/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.6032 - mse: 0.1996 - mace: 18.1378  
Epoch 00010: val_loss did not improve from 0.77708
1016/1016 [==============================] - 119s 117ms/step - loss: 0.6032 - mse: 0.1996 - mace: 18.1377 - val_loss: 0.8323 - val_mse: 0.3900 - val_mace: 25.4695
Epoch 11/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5953 - mse: 0.1943 - mace: 17.8460  
Epoch 00011: val_loss did not improve from 0.77708
1016/1016 [==============================] - 122s 120ms/step - loss: 0.5954 - mse: 0.1943 - mace: 17.8471 - val_loss: 0.8241 - val_mse: 0.3813 - val_mace: 25.1685
Epoch 12/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5952 - mse: 0.1941 - mace: 17.8355  
Epoch 00012: val_loss did not improve from 0.77708
1016/1016 [==============================] - 106s 104ms/step - loss: 0.5952 - mse: 0.1941 - mace: 17.8359 - val_loss: 0.7866 - val_mse: 0.3456 - val_mace: 23.9793
Epoch 13/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5916 - mse: 0.1922 - mace: 17.7353  
Epoch 00013: val_loss did not improve from 0.77708
1016/1016 [==============================] - 119s 118ms/step - loss: 0.5916 - mse: 0.1922 - mace: 17.7359 - val_loss: 0.8131 - val_mse: 0.3726 - val_mace: 24.8201
Epoch 14/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5903 - mse: 0.1915 - mace: 17.7284  
Epoch 00014: val_loss did not improve from 0.77708
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5903 - mse: 0.1915 - mace: 17.7292 - val_loss: 0.8091 - val_mse: 0.3689 - val_mace: 24.7407
Epoch 15/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5907 - mse: 0.1920 - mace: 17.7465  
Epoch 00015: val_loss improved from 0.77708 to 0.74787, saving model to checkpoint.h5
1016/1016 [==============================] - 119s 117ms/step - loss: 0.5907 - mse: 0.1920 - mace: 17.7472 - val_loss: 0.7479 - val_mse: 0.3156 - val_mace: 22.7949
Epoch 16/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5864 - mse: 0.1894 - mace: 17.6175  
Epoch 00016: val_loss did not improve from 0.74787
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5864 - mse: 0.1894 - mace: 17.6174 - val_loss: 0.7820 - val_mse: 0.3444 - val_mace: 23.8594
Epoch 17/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5858 - mse: 0.1892 - mace: 17.6034  
Epoch 00017: val_loss did not improve from 0.74787
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5857 - mse: 0.1892 - mace: 17.6021 - val_loss: 0.7773 - val_mse: 0.3404 - val_mace: 23.7412
Epoch 18/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5859 - mse: 0.1896 - mace: 17.6217  
Epoch 00018: val_loss did not improve from 0.74787
1016/1016 [==============================] - 109s 107ms/step - loss: 0.5859 - mse: 0.1896 - mace: 17.6233 - val_loss: 0.7853 - val_mse: 0.3476 - val_mace: 24.0134
Epoch 19/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5841 - mse: 0.1886 - mace: 17.5843  
Epoch 00019: val_loss did not improve from 0.74787
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5841 - mse: 0.1886 - mace: 17.5850 - val_loss: 0.8015 - val_mse: 0.3637 - val_mace: 24.5735
Epoch 20/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5796 - mse: 0.1863 - mace: 17.4652  
Epoch 00020: val_loss did not improve from 0.74787
1016/1016 [==============================] - 117s 116ms/step - loss: 0.5796 - mse: 0.1863 - mace: 17.4652 - val_loss: 0.7934 - val_mse: 0.3554 - val_mace: 24.2835
Epoch 21/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5721 - mse: 0.1811 - mace: 17.1636  
Epoch 00021: val_loss did not improve from 0.74787
1016/1016 [==============================] - 121s 119ms/step - loss: 0.5721 - mse: 0.1811 - mace: 17.1636 - val_loss: 0.7786 - val_mse: 0.3397 - val_mace: 23.6707
Epoch 22/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5739 - mse: 0.1810 - mace: 17.1738  
Epoch 00022: val_loss did not improve from 0.74787
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5740 - mse: 0.1810 - mace: 17.1741 - val_loss: 0.7963 - val_mse: 0.3570 - val_mace: 24.3088
Epoch 23/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5750 - mse: 0.1824 - mace: 17.2317  
Epoch 00023: val_loss did not improve from 0.74787
1016/1016 [==============================] - 116s 115ms/step - loss: 0.5749 - mse: 0.1823 - mace: 17.2283 - val_loss: 0.7486 - val_mse: 0.3146 - val_mace: 22.7842
Epoch 24/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5740 - mse: 0.1820 - mace: 17.2173  
Epoch 00024: val_loss did not improve from 0.74787
1016/1016 [==============================] - 108s 107ms/step - loss: 0.5739 - mse: 0.1820 - mace: 17.2165 - val_loss: 0.7540 - val_mse: 0.3180 - val_mace: 22.9713
Epoch 25/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5748 - mse: 0.1824 - mace: 17.2603  
Epoch 00025: val_loss did not improve from 0.74787
1016/1016 [==============================] - 126s 124ms/step - loss: 0.5748 - mse: 0.1825 - mace: 17.2614 - val_loss: 0.7918 - val_mse: 0.3562 - val_mace: 24.2205
Epoch 26/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5702 - mse: 0.1802 - mace: 17.1391  
Epoch 00026: val_loss did not improve from 0.74787
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5701 - mse: 0.1802 - mace: 17.1379 - val_loss: 0.7716 - val_mse: 0.3374 - val_mace: 23.5860
Epoch 27/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5710 - mse: 0.1805 - mace: 17.1502  
Epoch 00027: val_loss did not improve from 0.74787
1016/1016 [==============================] - 120s 118ms/step - loss: 0.5710 - mse: 0.1805 - mace: 17.1495 - val_loss: 0.7701 - val_mse: 0.3347 - val_mace: 23.5430
Epoch 28/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5689 - mse: 0.1796 - mace: 17.1111  
Epoch 00028: val_loss did not improve from 0.74787
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5690 - mse: 0.1796 - mace: 17.1115 - val_loss: 0.8066 - val_mse: 0.3699 - val_mace: 24.7227
Epoch 29/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5697 - mse: 0.1801 - mace: 17.1307  
Epoch 00029: val_loss did not improve from 0.74787
1016/1016 [==============================] - 122s 120ms/step - loss: 0.5697 - mse: 0.1801 - mace: 17.1316 - val_loss: 0.7785 - val_mse: 0.3439 - val_mace: 23.8202
Epoch 30/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5683 - mse: 0.1794 - mace: 17.0942  
Epoch 00030: val_loss did not improve from 0.74787
1016/1016 [==============================] - 108s 106ms/step - loss: 0.5682 - mse: 0.1794 - mace: 17.0933 - val_loss: 0.7583 - val_mse: 0.3253 - val_mace: 23.1647
Epoch 31/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5618 - mse: 0.1747 - mace: 16.8225  
Epoch 00031: val_loss did not improve from 0.74787
1016/1016 [==============================] - 124s 122ms/step - loss: 0.5618 - mse: 0.1747 - mace: 16.8227 - val_loss: 0.8034 - val_mse: 0.3632 - val_mace: 24.5094
Epoch 32/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5645 - mse: 0.1759 - mace: 16.8934  
Epoch 00032: val_loss did not improve from 0.74787
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5645 - mse: 0.1759 - mace: 16.8925 - val_loss: 0.7920 - val_mse: 0.3527 - val_mace: 24.1874
Epoch 33/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5601 - mse: 0.1738 - mace: 16.7703  
Epoch 00033: val_loss improved from 0.74787 to 0.72935, saving model to checkpoint.h5
1016/1016 [==============================] - 118s 117ms/step - loss: 0.5601 - mse: 0.1737 - mace: 16.7691 - val_loss: 0.7294 - val_mse: 0.2992 - val_mace: 22.1995
Epoch 34/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5623 - mse: 0.1747 - mace: 16.8480  
Epoch 00034: val_loss did not improve from 0.72935
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5624 - mse: 0.1747 - mace: 16.8485 - val_loss: 0.7401 - val_mse: 0.3080 - val_mace: 22.5321
Epoch 35/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5594 - mse: 0.1737 - mace: 16.7729  
Epoch 00035: val_loss did not improve from 0.72935
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5594 - mse: 0.1737 - mace: 16.7722 - val_loss: 0.7702 - val_mse: 0.3347 - val_mace: 23.5205
Epoch 36/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5615 - mse: 0.1753 - mace: 16.8579  
Epoch 00036: val_loss did not improve from 0.72935
1016/1016 [==============================] - 108s 106ms/step - loss: 0.5615 - mse: 0.1753 - mace: 16.8583 - val_loss: 0.8198 - val_mse: 0.3796 - val_mace: 25.1166
Epoch 37/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5627 - mse: 0.1754 - mace: 16.8921  
Epoch 00037: val_loss did not improve from 0.72935
1016/1016 [==============================] - 114s 112ms/step - loss: 0.5627 - mse: 0.1754 - mace: 16.8926 - val_loss: 0.7927 - val_mse: 0.3566 - val_mace: 24.2602
Epoch 38/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5601 - mse: 0.1744 - mace: 16.8150  
Epoch 00038: val_loss did not improve from 0.72935
1016/1016 [==============================] - 131s 129ms/step - loss: 0.5600 - mse: 0.1743 - mace: 16.8129 - val_loss: 0.7635 - val_mse: 0.3299 - val_mace: 23.3000
Epoch 39/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5598 - mse: 0.1741 - mace: 16.8100  
Epoch 00039: val_loss did not improve from 0.72935
1016/1016 [==============================] - 116s 115ms/step - loss: 0.5598 - mse: 0.1741 - mace: 16.8095 - val_loss: 0.7943 - val_mse: 0.3562 - val_mace: 24.3168
Epoch 40/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5597 - mse: 0.1738 - mace: 16.8091  
Epoch 00040: val_loss did not improve from 0.72935
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5596 - mse: 0.1738 - mace: 16.8086 - val_loss: 0.7513 - val_mse: 0.3183 - val_mace: 22.9306
Epoch 41/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5514 - mse: 0.1688 - mace: 16.5263  
Epoch 00041: val_loss did not improve from 0.72935
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5515 - mse: 0.1688 - mace: 16.5272 - val_loss: 0.8609 - val_mse: 0.4186 - val_mace: 26.4143
Epoch 42/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5519 - mse: 0.1691 - mace: 16.5286  
Epoch 00042: val_loss did not improve from 0.72935
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5519 - mse: 0.1691 - mace: 16.5287 - val_loss: 0.8140 - val_mse: 0.3757 - val_mace: 24.9311
Epoch 43/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5516 - mse: 0.1691 - mace: 16.5273  
Epoch 00043: val_loss did not improve from 0.72935
1016/1016 [==============================] - 117s 116ms/step - loss: 0.5516 - mse: 0.1691 - mace: 16.5269 - val_loss: 0.8279 - val_mse: 0.3871 - val_mace: 25.3740
Epoch 44/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5543 - mse: 0.1705 - mace: 16.6151  
Epoch 00044: val_loss did not improve from 0.72935
1016/1016 [==============================] - 114s 113ms/step - loss: 0.5543 - mse: 0.1705 - mace: 16.6153 - val_loss: 0.7441 - val_mse: 0.3132 - val_mace: 22.7032
Epoch 45/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5526 - mse: 0.1695 - mace: 16.5615  
Epoch 00045: val_loss did not improve from 0.72935
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5526 - mse: 0.1695 - mace: 16.5613 - val_loss: 0.7579 - val_mse: 0.3257 - val_mace: 23.1395
Epoch 46/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5528 - mse: 0.1700 - mace: 16.5822  
Epoch 00046: val_loss did not improve from 0.72935
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5528 - mse: 0.1700 - mace: 16.5822 - val_loss: 0.8140 - val_mse: 0.3748 - val_mace: 24.9414
Epoch 47/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5514 - mse: 0.1694 - mace: 16.5467  
Epoch 00047: val_loss did not improve from 0.72935
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5514 - mse: 0.1694 - mace: 16.5479 - val_loss: 0.7453 - val_mse: 0.3137 - val_mace: 22.7451
Epoch 48/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5514 - mse: 0.1695 - mace: 16.5391  
Epoch 00048: val_loss did not improve from 0.72935
1016/1016 [==============================] - 109s 108ms/step - loss: 0.5514 - mse: 0.1694 - mace: 16.5382 - val_loss: 0.8076 - val_mse: 0.3700 - val_mace: 24.7149
Epoch 49/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5539 - mse: 0.1709 - mace: 16.6152  
Epoch 00049: val_loss did not improve from 0.72935
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5539 - mse: 0.1709 - mace: 16.6141 - val_loss: 0.7736 - val_mse: 0.3406 - val_mace: 23.6747
Epoch 50/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5536 - mse: 0.1707 - mace: 16.6198  
Epoch 00050: val_loss improved from 0.72935 to 0.72006, saving model to checkpoint.h5
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5537 - mse: 0.1707 - mace: 16.6207 - val_loss: 0.7201 - val_mse: 0.2931 - val_mace: 21.9721
Epoch 51/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5441 - mse: 0.1653 - mace: 16.3143  
Epoch 00051: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5441 - mse: 0.1653 - mace: 16.3143 - val_loss: 0.7946 - val_mse: 0.3575 - val_mace: 24.3131
Epoch 52/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5443 - mse: 0.1649 - mace: 16.2830  
Epoch 00052: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 121ms/step - loss: 0.5443 - mse: 0.1649 - mace: 16.2839 - val_loss: 0.8107 - val_mse: 0.3720 - val_mace: 24.8176
Epoch 53/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5472 - mse: 0.1660 - mace: 16.3636  
Epoch 00053: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5471 - mse: 0.1659 - mace: 16.3619 - val_loss: 0.7952 - val_mse: 0.3576 - val_mace: 24.3282
Epoch 54/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5442 - mse: 0.1645 - mace: 16.2784  
Epoch 00054: val_loss did not improve from 0.72006
1016/1016 [==============================] - 107s 105ms/step - loss: 0.5442 - mse: 0.1644 - mace: 16.2778 - val_loss: 0.7778 - val_mse: 0.3431 - val_mace: 23.7516
Epoch 55/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5462 - mse: 0.1658 - mace: 16.3446  
Epoch 00055: val_loss did not improve from 0.72006
1016/1016 [==============================] - 120s 118ms/step - loss: 0.5461 - mse: 0.1658 - mace: 16.3432 - val_loss: 0.7918 - val_mse: 0.3545 - val_mace: 24.2164
Epoch 56/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5460 - mse: 0.1658 - mace: 16.3574  
Epoch 00056: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 121ms/step - loss: 0.5460 - mse: 0.1658 - mace: 16.3579 - val_loss: 0.8066 - val_mse: 0.3689 - val_mace: 24.6950
Epoch 57/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5463 - mse: 0.1660 - mace: 16.3660  
Epoch 00057: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5463 - mse: 0.1660 - mace: 16.3661 - val_loss: 0.7696 - val_mse: 0.3364 - val_mace: 23.5320
Epoch 58/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5466 - mse: 0.1665 - mace: 16.3963  
Epoch 00058: val_loss did not improve from 0.72006
1016/1016 [==============================] - 126s 124ms/step - loss: 0.5466 - mse: 0.1665 - mace: 16.3960 - val_loss: 0.8178 - val_mse: 0.3808 - val_mace: 25.0745
Epoch 59/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5473 - mse: 0.1671 - mace: 16.4213  
Epoch 00059: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 105ms/step - loss: 0.5473 - mse: 0.1671 - mace: 16.4211 - val_loss: 0.7735 - val_mse: 0.3379 - val_mace: 23.6690
Epoch 60/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5449 - mse: 0.1656 - mace: 16.3455  
Epoch 00060: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 115ms/step - loss: 0.5449 - mse: 0.1656 - mace: 16.3459 - val_loss: 0.7257 - val_mse: 0.2991 - val_mace: 22.1490
Epoch 61/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5361 - mse: 0.1604 - mace: 16.0307  
Epoch 00061: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5361 - mse: 0.1604 - mace: 16.0313 - val_loss: 0.8008 - val_mse: 0.3624 - val_mace: 24.4810
Epoch 62/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5375 - mse: 0.1603 - mace: 16.0521  
Epoch 00062: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 121ms/step - loss: 0.5376 - mse: 0.1603 - mace: 16.0522 - val_loss: 0.7604 - val_mse: 0.3265 - val_mace: 23.1751
Epoch 63/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5394 - mse: 0.1615 - mace: 16.1116  
Epoch 00063: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5395 - mse: 0.1615 - mace: 16.1117 - val_loss: 0.7781 - val_mse: 0.3430 - val_mace: 23.7732
Epoch 64/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5412 - mse: 0.1629 - mace: 16.1830  
Epoch 00064: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 117ms/step - loss: 0.5412 - mse: 0.1629 - mace: 16.1827 - val_loss: 0.8246 - val_mse: 0.3857 - val_mace: 25.2660
Epoch 65/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5407 - mse: 0.1623 - mace: 16.1729  
Epoch 00065: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 122ms/step - loss: 0.5407 - mse: 0.1623 - mace: 16.1726 - val_loss: 0.8204 - val_mse: 0.3800 - val_mace: 25.0980
Epoch 66/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5423 - mse: 0.1634 - mace: 16.2065  
Epoch 00066: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 114ms/step - loss: 0.5424 - mse: 0.1634 - mace: 16.2081 - val_loss: 0.8002 - val_mse: 0.3625 - val_mace: 24.4652
Epoch 67/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5409 - mse: 0.1626 - mace: 16.1718  
Epoch 00067: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.5409 - mse: 0.1626 - mace: 16.1724 - val_loss: 0.7560 - val_mse: 0.3220 - val_mace: 23.0597
Epoch 68/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5401 - mse: 0.1624 - mace: 16.1555  
Epoch 00068: val_loss did not improve from 0.72006
1016/1016 [==============================] - 113s 112ms/step - loss: 0.5401 - mse: 0.1624 - mace: 16.1548 - val_loss: 0.7374 - val_mse: 0.3067 - val_mace: 22.4868
Epoch 69/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5409 - mse: 0.1629 - mace: 16.1907  
Epoch 00069: val_loss did not improve from 0.72006
1016/1016 [==============================] - 136s 134ms/step - loss: 0.5409 - mse: 0.1629 - mace: 16.1915 - val_loss: 0.7306 - val_mse: 0.2992 - val_mace: 22.2251
Epoch 70/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5426 - mse: 0.1638 - mace: 16.2246  
Epoch 00070: val_loss did not improve from 0.72006
1016/1016 [==============================] - 124s 122ms/step - loss: 0.5426 - mse: 0.1638 - mace: 16.2257 - val_loss: 0.8725 - val_mse: 0.4290 - val_mace: 26.7876
Epoch 71/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5324 - mse: 0.1568 - mace: 15.8282  
Epoch 00071: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 113ms/step - loss: 0.5324 - mse: 0.1568 - mace: 15.8285 - val_loss: 0.7910 - val_mse: 0.3519 - val_mace: 24.0959
Epoch 72/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5319 - mse: 0.1567 - mace: 15.8281  
Epoch 00072: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 104ms/step - loss: 0.5319 - mse: 0.1567 - mace: 15.8279 - val_loss: 0.7900 - val_mse: 0.3533 - val_mace: 24.1081
Epoch 73/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5351 - mse: 0.1583 - mace: 15.9433   
Epoch 00073: val_loss did not improve from 0.72006
1016/1016 [==============================] - 133s 131ms/step - loss: 0.5351 - mse: 0.1583 - mace: 15.9433 - val_loss: 0.7506 - val_mse: 0.3176 - val_mace: 22.8394
Epoch 74/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5343 - mse: 0.1581 - mace: 15.9290  
Epoch 00074: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 114ms/step - loss: 0.5343 - mse: 0.1581 - mace: 15.9294 - val_loss: 0.7907 - val_mse: 0.3531 - val_mace: 24.1264
Epoch 75/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5357 - mse: 0.1590 - mace: 15.9663  
Epoch 00075: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.5357 - mse: 0.1590 - mace: 15.9669 - val_loss: 0.8415 - val_mse: 0.3990 - val_mace: 25.7456
Epoch 76/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5347 - mse: 0.1587 - mace: 15.9533  
Epoch 00076: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5346 - mse: 0.1586 - mace: 15.9530 - val_loss: 0.7819 - val_mse: 0.3456 - val_mace: 23.8771
Epoch 77/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5390 - mse: 0.1613 - mace: 16.0957  
Epoch 00077: val_loss did not improve from 0.72006
1016/1016 [==============================] - 124s 122ms/step - loss: 0.5390 - mse: 0.1613 - mace: 16.0948 - val_loss: 0.8536 - val_mse: 0.4110 - val_mace: 26.1648
Epoch 78/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5363 - mse: 0.1598 - mace: 16.0107  
Epoch 00078: val_loss did not improve from 0.72006
1016/1016 [==============================] - 110s 108ms/step - loss: 0.5362 - mse: 0.1598 - mace: 16.0089 - val_loss: 0.7905 - val_mse: 0.3540 - val_mace: 24.1567
Epoch 79/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5375 - mse: 0.1609 - mace: 16.0746  
Epoch 00079: val_loss did not improve from 0.72006
1016/1016 [==============================] - 139s 137ms/step - loss: 0.5375 - mse: 0.1609 - mace: 16.0749 - val_loss: 0.7896 - val_mse: 0.3540 - val_mace: 24.1450
Epoch 80/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5348 - mse: 0.1596 - mace: 15.9983  
Epoch 00080: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5348 - mse: 0.1596 - mace: 15.9991 - val_loss: 0.7325 - val_mse: 0.3012 - val_mace: 22.3205
Epoch 81/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5240 - mse: 0.1528 - mace: 15.6127  
Epoch 00081: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5239 - mse: 0.1528 - mace: 15.6114 - val_loss: 0.7584 - val_mse: 0.3231 - val_mace: 23.0931
Epoch 82/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5226 - mse: 0.1517 - mace: 15.5317  
Epoch 00082: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5226 - mse: 0.1517 - mace: 15.5329 - val_loss: 0.8078 - val_mse: 0.3684 - val_mace: 24.6635
Epoch 83/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5261 - mse: 0.1534 - mace: 15.6432  
Epoch 00083: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5261 - mse: 0.1534 - mace: 15.6439 - val_loss: 0.8188 - val_mse: 0.3773 - val_mace: 25.0014
Epoch 84/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5308 - mse: 0.1565 - mace: 15.8038  
Epoch 00084: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 104ms/step - loss: 0.5308 - mse: 0.1565 - mace: 15.8033 - val_loss: 0.7524 - val_mse: 0.3182 - val_mace: 22.8986
Epoch 85/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5313 - mse: 0.1566 - mace: 15.8244  
Epoch 00085: val_loss did not improve from 0.72006
1016/1016 [==============================] - 131s 129ms/step - loss: 0.5313 - mse: 0.1566 - mace: 15.8241 - val_loss: 0.7746 - val_mse: 0.3387 - val_mace: 23.6164
Epoch 86/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5322 - mse: 0.1572 - mace: 15.8621  
Epoch 00086: val_loss did not improve from 0.72006
1016/1016 [==============================] - 120s 118ms/step - loss: 0.5322 - mse: 0.1572 - mace: 15.8606 - val_loss: 0.7721 - val_mse: 0.3366 - val_mace: 23.5276
Epoch 87/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5310 - mse: 0.1565 - mace: 15.8154  
Epoch 00087: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 112ms/step - loss: 0.5310 - mse: 0.1565 - mace: 15.8154 - val_loss: 0.8158 - val_mse: 0.3761 - val_mace: 24.9268
Epoch 88/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5323 - mse: 0.1570 - mace: 15.8695  
Epoch 00088: val_loss did not improve from 0.72006
1016/1016 [==============================] - 119s 117ms/step - loss: 0.5323 - mse: 0.1570 - mace: 15.8690 - val_loss: 0.7587 - val_mse: 0.3251 - val_mace: 23.1235
Epoch 89/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5317 - mse: 0.1572 - mace: 15.8595  
Epoch 00089: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5317 - mse: 0.1572 - mace: 15.8609 - val_loss: 0.7675 - val_mse: 0.3323 - val_mace: 23.4302
Epoch 90/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5322 - mse: 0.1575 - mace: 15.8825  
Epoch 00090: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5322 - mse: 0.1575 - mace: 15.8827 - val_loss: 0.7414 - val_mse: 0.3111 - val_mace: 22.5895
Epoch 91/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5200 - mse: 0.1498 - mace: 15.4409  
Epoch 00091: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 112ms/step - loss: 0.5200 - mse: 0.1498 - mace: 15.4411 - val_loss: 0.7603 - val_mse: 0.3250 - val_mace: 23.1083
Epoch 92/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5239 - mse: 0.1520 - mace: 15.5712  
Epoch 00092: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5239 - mse: 0.1519 - mace: 15.5703 - val_loss: 0.7672 - val_mse: 0.3312 - val_mace: 23.3570
Epoch 93/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5245 - mse: 0.1522 - mace: 15.5871  
Epoch 00093: val_loss did not improve from 0.72006
1016/1016 [==============================] - 130s 128ms/step - loss: 0.5245 - mse: 0.1522 - mace: 15.5867 - val_loss: 0.8611 - val_mse: 0.4190 - val_mace: 26.3689
Epoch 94/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5223 - mse: 0.1514 - mace: 15.5271  
Epoch 00094: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5223 - mse: 0.1514 - mace: 15.5257 - val_loss: 0.8164 - val_mse: 0.3768 - val_mace: 24.9338
Epoch 95/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5253 - mse: 0.1529 - mace: 15.6225  
Epoch 00095: val_loss did not improve from 0.72006
1016/1016 [==============================] - 105s 103ms/step - loss: 0.5253 - mse: 0.1529 - mace: 15.6234 - val_loss: 0.7893 - val_mse: 0.3518 - val_mace: 24.0846
Epoch 96/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5246 - mse: 0.1527 - mace: 15.6140  
Epoch 00096: val_loss did not improve from 0.72006
1016/1016 [==============================] - 111s 109ms/step - loss: 0.5246 - mse: 0.1527 - mace: 15.6133 - val_loss: 0.7662 - val_mse: 0.3320 - val_mace: 23.3489
Epoch 97/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5265 - mse: 0.1538 - mace: 15.6676  
Epoch 00097: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.5264 - mse: 0.1538 - mace: 15.6669 - val_loss: 0.8169 - val_mse: 0.3765 - val_mace: 24.9655
Epoch 98/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5267 - mse: 0.1542 - mace: 15.6947  
Epoch 00098: val_loss did not improve from 0.72006
1016/1016 [==============================] - 113s 112ms/step - loss: 0.5267 - mse: 0.1542 - mace: 15.6946 - val_loss: 0.8119 - val_mse: 0.3740 - val_mace: 24.8365
Epoch 99/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5269 - mse: 0.1542 - mace: 15.6946  
Epoch 00099: val_loss did not improve from 0.72006
1016/1016 [==============================] - 134s 132ms/step - loss: 0.5269 - mse: 0.1542 - mace: 15.6957 - val_loss: 0.7813 - val_mse: 0.3434 - val_mace: 23.8190
Epoch 100/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5290 - mse: 0.1551 - mace: 15.7612  
Epoch 00100: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5289 - mse: 0.1551 - mace: 15.7595 - val_loss: 0.8050 - val_mse: 0.3672 - val_mace: 24.5757
Epoch 101/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5168 - mse: 0.1480 - mace: 15.3340  
Epoch 00101: val_loss did not improve from 0.72006
1016/1016 [==============================] - 119s 117ms/step - loss: 0.5167 - mse: 0.1480 - mace: 15.3326 - val_loss: 0.8284 - val_mse: 0.3862 - val_mace: 25.2939
Epoch 102/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5176 - mse: 0.1481 - mace: 15.3463  
Epoch 00102: val_loss did not improve from 0.72006
1016/1016 [==============================] - 108s 106ms/step - loss: 0.5176 - mse: 0.1481 - mace: 15.3470 - val_loss: 0.7960 - val_mse: 0.3573 - val_mace: 24.2558
Epoch 103/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5184 - mse: 0.1490 - mace: 15.3932  
Epoch 00103: val_loss did not improve from 0.72006
1016/1016 [==============================] - 121s 119ms/step - loss: 0.5184 - mse: 0.1490 - mace: 15.3934 - val_loss: 0.7699 - val_mse: 0.3356 - val_mace: 23.4638
Epoch 104/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5203 - mse: 0.1501 - mace: 15.4647  
Epoch 00104: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5203 - mse: 0.1501 - mace: 15.4651 - val_loss: 0.7939 - val_mse: 0.3565 - val_mace: 24.2145
Epoch 105/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5175 - mse: 0.1486 - mace: 15.3779  
Epoch 00105: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5175 - mse: 0.1486 - mace: 15.3788 - val_loss: 0.7842 - val_mse: 0.3477 - val_mace: 23.9205
Epoch 106/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5187 - mse: 0.1491 - mace: 15.4090  
Epoch 00106: val_loss did not improve from 0.72006
1016/1016 [==============================] - 126s 124ms/step - loss: 0.5187 - mse: 0.1491 - mace: 15.4087 - val_loss: 0.8571 - val_mse: 0.4127 - val_mace: 26.2286
Epoch 107/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5228 - mse: 0.1516 - mace: 15.5523  
Epoch 00107: val_loss did not improve from 0.72006
1016/1016 [==============================] - 108s 106ms/step - loss: 0.5229 - mse: 0.1516 - mace: 15.5545 - val_loss: 0.8189 - val_mse: 0.3786 - val_mace: 25.0249
Epoch 108/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5212 - mse: 0.1513 - mace: 15.5332  
Epoch 00108: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 104ms/step - loss: 0.5213 - mse: 0.1514 - mace: 15.5341 - val_loss: 0.7819 - val_mse: 0.3448 - val_mace: 23.8598
Epoch 109/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5232 - mse: 0.1521 - mace: 15.5731  
Epoch 00109: val_loss did not improve from 0.72006
1016/1016 [==============================] - 138s 136ms/step - loss: 0.5232 - mse: 0.1521 - mace: 15.5749 - val_loss: 0.7988 - val_mse: 0.3599 - val_mace: 24.3944
Epoch 110/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5221 - mse: 0.1514 - mace: 15.5433  
Epoch 00110: val_loss did not improve from 0.72006
1016/1016 [==============================] - 127s 125ms/step - loss: 0.5221 - mse: 0.1514 - mace: 15.5436 - val_loss: 0.7998 - val_mse: 0.3609 - val_mace: 24.4189
Epoch 111/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5107 - mse: 0.1446 - mace: 15.1460  
Epoch 00111: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5107 - mse: 0.1445 - mace: 15.1456 - val_loss: 0.8652 - val_mse: 0.4213 - val_mace: 26.4466
Epoch 112/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5117 - mse: 0.1451 - mace: 15.1676  
Epoch 00112: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5117 - mse: 0.1451 - mace: 15.1664 - val_loss: 0.7679 - val_mse: 0.3313 - val_mace: 23.3618
Epoch 113/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5121 - mse: 0.1452 - mace: 15.1811  
Epoch 00113: val_loss did not improve from 0.72006
1016/1016 [==============================] - 120s 118ms/step - loss: 0.5121 - mse: 0.1452 - mace: 15.1796 - val_loss: 0.7916 - val_mse: 0.3546 - val_mace: 24.1071
Epoch 114/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5144 - mse: 0.1466 - mace: 15.2492  
Epoch 00114: val_loss did not improve from 0.72006
1016/1016 [==============================] - 127s 125ms/step - loss: 0.5144 - mse: 0.1466 - mace: 15.2491 - val_loss: 0.8491 - val_mse: 0.4060 - val_mace: 25.9631
Epoch 115/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5159 - mse: 0.1474 - mace: 15.3014  
Epoch 00115: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5159 - mse: 0.1474 - mace: 15.3010 - val_loss: 0.8057 - val_mse: 0.3656 - val_mace: 24.5661
Epoch 116/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5145 - mse: 0.1465 - mace: 15.2708  
Epoch 00116: val_loss did not improve from 0.72006
1016/1016 [==============================] - 140s 138ms/step - loss: 0.5146 - mse: 0.1465 - mace: 15.2726 - val_loss: 0.7647 - val_mse: 0.3305 - val_mace: 23.2882
Epoch 117/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5163 - mse: 0.1477 - mace: 15.3276  
Epoch 00117: val_loss did not improve from 0.72006
1016/1016 [==============================] - 120s 118ms/step - loss: 0.5163 - mse: 0.1477 - mace: 15.3278 - val_loss: 0.7903 - val_mse: 0.3527 - val_mace: 24.0898
Epoch 118/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5201 - mse: 0.1498 - mace: 15.4433  
Epoch 00118: val_loss did not improve from 0.72006
1016/1016 [==============================] - 113s 111ms/step - loss: 0.5201 - mse: 0.1498 - mace: 15.4436 - val_loss: 0.7517 - val_mse: 0.3188 - val_mace: 22.8589
Epoch 119/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5201 - mse: 0.1501 - mace: 15.4668  
Epoch 00119: val_loss did not improve from 0.72006
1016/1016 [==============================] - 112s 110ms/step - loss: 0.5201 - mse: 0.1501 - mace: 15.4665 - val_loss: 0.7692 - val_mse: 0.3337 - val_mace: 23.4313
Epoch 120/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5206 - mse: 0.1506 - mace: 15.4847  
Epoch 00120: val_loss did not improve from 0.72006
1016/1016 [==============================] - 132s 130ms/step - loss: 0.5205 - mse: 0.1506 - mace: 15.4833 - val_loss: 0.8002 - val_mse: 0.3627 - val_mace: 24.4371
Epoch 121/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5087 - mse: 0.1439 - mace: 15.1009  
Epoch 00121: val_loss did not improve from 0.72006
1016/1016 [==============================] - 113s 112ms/step - loss: 0.5087 - mse: 0.1439 - mace: 15.0998 - val_loss: 0.8274 - val_mse: 0.3852 - val_mace: 25.2828
Epoch 122/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5044 - mse: 0.1411 - mace: 14.9342  
Epoch 00122: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5044 - mse: 0.1411 - mace: 14.9345 - val_loss: 0.7590 - val_mse: 0.3235 - val_mace: 23.0590
Epoch 123/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5069 - mse: 0.1422 - mace: 14.9980  
Epoch 00123: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5070 - mse: 0.1422 - mace: 14.9991 - val_loss: 0.7434 - val_mse: 0.3104 - val_mace: 22.5572
Epoch 124/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5114 - mse: 0.1444 - mace: 15.1411  
Epoch 00124: val_loss did not improve from 0.72006
1016/1016 [==============================] - 124s 122ms/step - loss: 0.5114 - mse: 0.1444 - mace: 15.1417 - val_loss: 0.8362 - val_mse: 0.3952 - val_mace: 25.5624
Epoch 125/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5112 - mse: 0.1445 - mace: 15.1521  
Epoch 00125: val_loss did not improve from 0.72006
1016/1016 [==============================] - 107s 105ms/step - loss: 0.5112 - mse: 0.1445 - mace: 15.1505 - val_loss: 0.8138 - val_mse: 0.3731 - val_mace: 24.8242
Epoch 126/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5103 - mse: 0.1443 - mace: 15.1308  
Epoch 00126: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5103 - mse: 0.1443 - mace: 15.1312 - val_loss: 0.8080 - val_mse: 0.3684 - val_mace: 24.6429
Epoch 127/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5151 - mse: 0.1470 - mace: 15.2852  
Epoch 00127: val_loss did not improve from 0.72006
1016/1016 [==============================] - 119s 117ms/step - loss: 0.5151 - mse: 0.1471 - mace: 15.2855 - val_loss: 0.7731 - val_mse: 0.3369 - val_mace: 23.5556
Epoch 128/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5128 - mse: 0.1460 - mace: 15.2218  
Epoch 00128: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5127 - mse: 0.1459 - mace: 15.2203 - val_loss: 0.7454 - val_mse: 0.3128 - val_mace: 22.6640
Epoch 129/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5131 - mse: 0.1459 - mace: 15.2297  
Epoch 00129: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5131 - mse: 0.1459 - mace: 15.2288 - val_loss: 0.7763 - val_mse: 0.3410 - val_mace: 23.6494
Epoch 130/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5139 - mse: 0.1464 - mace: 15.2551  
Epoch 00130: val_loss did not improve from 0.72006
1016/1016 [==============================] - 124s 122ms/step - loss: 0.5139 - mse: 0.1464 - mace: 15.2540 - val_loss: 0.8651 - val_mse: 0.4233 - val_mace: 26.5076
Epoch 131/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5043 - mse: 0.1408 - mace: 14.9245  
Epoch 00131: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 104ms/step - loss: 0.5043 - mse: 0.1408 - mace: 14.9239 - val_loss: 0.8587 - val_mse: 0.4158 - val_mace: 26.2581
Epoch 132/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5040 - mse: 0.1405 - mace: 14.8984  
Epoch 00132: val_loss did not improve from 0.72006
1016/1016 [==============================] - 103s 101ms/step - loss: 0.5039 - mse: 0.1405 - mace: 14.8979 - val_loss: 0.7768 - val_mse: 0.3395 - val_mace: 23.6249
Epoch 133/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5020 - mse: 0.1394 - mace: 14.8465  
Epoch 00133: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5020 - mse: 0.1394 - mace: 14.8457 - val_loss: 0.7280 - val_mse: 0.2969 - val_mace: 22.0882
Epoch 134/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5061 - mse: 0.1416 - mace: 14.9784  
Epoch 00134: val_loss did not improve from 0.72006
1016/1016 [==============================] - 131s 129ms/step - loss: 0.5061 - mse: 0.1416 - mace: 14.9783 - val_loss: 0.8197 - val_mse: 0.3796 - val_mace: 25.0041
Epoch 135/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5085 - mse: 0.1431 - mace: 15.0633  
Epoch 00135: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5085 - mse: 0.1431 - mace: 15.0630 - val_loss: 0.7876 - val_mse: 0.3503 - val_mace: 24.0004
Epoch 136/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5080 - mse: 0.1429 - mace: 15.0411  
Epoch 00136: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5080 - mse: 0.1429 - mace: 15.0417 - val_loss: 0.8088 - val_mse: 0.3697 - val_mace: 24.6766
Epoch 137/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5090 - mse: 0.1434 - mace: 15.0798  
Epoch 00137: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 105ms/step - loss: 0.5090 - mse: 0.1434 - mace: 15.0790 - val_loss: 0.7983 - val_mse: 0.3594 - val_mace: 24.3425
Epoch 138/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5082 - mse: 0.1432 - mace: 15.0750  
Epoch 00138: val_loss did not improve from 0.72006
1016/1016 [==============================] - 129s 127ms/step - loss: 0.5082 - mse: 0.1432 - mace: 15.0757 - val_loss: 0.7382 - val_mse: 0.3079 - val_mace: 22.4380
Epoch 139/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5106 - mse: 0.1443 - mace: 15.1452  
Epoch 00139: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5106 - mse: 0.1443 - mace: 15.1453 - val_loss: 0.7690 - val_mse: 0.3320 - val_mace: 23.4089
Epoch 140/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5115 - mse: 0.1449 - mace: 15.1688  
Epoch 00140: val_loss did not improve from 0.72006
1016/1016 [==============================] - 112s 110ms/step - loss: 0.5115 - mse: 0.1449 - mace: 15.1684 - val_loss: 0.7733 - val_mse: 0.3385 - val_mace: 23.5492
Epoch 141/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5005 - mse: 0.1389 - mace: 14.8155  
Epoch 00141: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 121ms/step - loss: 0.5006 - mse: 0.1389 - mace: 14.8160 - val_loss: 0.7730 - val_mse: 0.3349 - val_mace: 23.4966
Epoch 142/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4991 - mse: 0.1375 - mace: 14.7392  
Epoch 00142: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.4991 - mse: 0.1375 - mace: 14.7396 - val_loss: 0.8178 - val_mse: 0.3776 - val_mace: 24.9519
Epoch 143/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4974 - mse: 0.1368 - mace: 14.6833  
Epoch 00143: val_loss did not improve from 0.72006
1016/1016 [==============================] - 107s 105ms/step - loss: 0.4974 - mse: 0.1368 - mace: 14.6840 - val_loss: 0.7655 - val_mse: 0.3302 - val_mace: 23.2510
Epoch 144/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5047 - mse: 0.1405 - mace: 14.9158  
Epoch 00144: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.5047 - mse: 0.1405 - mace: 14.9162 - val_loss: 0.7968 - val_mse: 0.3590 - val_mace: 24.2658
Epoch 145/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5024 - mse: 0.1397 - mace: 14.8611  
Epoch 00145: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5024 - mse: 0.1397 - mace: 14.8606 - val_loss: 0.7576 - val_mse: 0.3249 - val_mace: 23.0433
Epoch 146/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5059 - mse: 0.1416 - mace: 14.9804  
Epoch 00146: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5059 - mse: 0.1416 - mace: 14.9793 - val_loss: 0.7915 - val_mse: 0.3542 - val_mace: 24.1271
Epoch 147/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5055 - mse: 0.1413 - mace: 14.9643  
Epoch 00147: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.5054 - mse: 0.1413 - mace: 14.9625 - val_loss: 0.8011 - val_mse: 0.3611 - val_mace: 24.4046
Epoch 148/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5074 - mse: 0.1425 - mace: 15.0149  
Epoch 00148: val_loss did not improve from 0.72006
1016/1016 [==============================] - 109s 107ms/step - loss: 0.5074 - mse: 0.1425 - mace: 15.0160 - val_loss: 0.7352 - val_mse: 0.3058 - val_mace: 22.3141
Epoch 149/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5073 - mse: 0.1424 - mace: 15.0276  
Epoch 00149: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5073 - mse: 0.1424 - mace: 15.0278 - val_loss: 0.7542 - val_mse: 0.3204 - val_mace: 22.9284
Epoch 150/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5081 - mse: 0.1431 - mace: 15.0587  
Epoch 00150: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.5081 - mse: 0.1431 - mace: 15.0585 - val_loss: 0.8427 - val_mse: 0.3980 - val_mace: 25.7619
Epoch 151/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4966 - mse: 0.1364 - mace: 14.6789  
Epoch 00151: val_loss did not improve from 0.72006
1016/1016 [==============================] - 120s 118ms/step - loss: 0.4966 - mse: 0.1364 - mace: 14.6792 - val_loss: 0.7946 - val_mse: 0.3573 - val_mace: 24.1994
Epoch 152/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4921 - mse: 0.1337 - mace: 14.5224  
Epoch 00152: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.4921 - mse: 0.1337 - mace: 14.5235 - val_loss: 0.8418 - val_mse: 0.3997 - val_mace: 25.7239
Epoch 153/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4989 - mse: 0.1375 - mace: 14.7417  
Epoch 00153: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.4989 - mse: 0.1375 - mace: 14.7424 - val_loss: 0.8270 - val_mse: 0.3845 - val_mace: 25.2446
Epoch 154/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5001 - mse: 0.1385 - mace: 14.7873  
Epoch 00154: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.5001 - mse: 0.1385 - mace: 14.7867 - val_loss: 0.7804 - val_mse: 0.3408 - val_mace: 23.7271
Epoch 155/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4990 - mse: 0.1377 - mace: 14.7551  
Epoch 00155: val_loss did not improve from 0.72006
1016/1016 [==============================] - 107s 106ms/step - loss: 0.4990 - mse: 0.1377 - mace: 14.7551 - val_loss: 0.7697 - val_mse: 0.3346 - val_mace: 23.4114
Epoch 156/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5001 - mse: 0.1385 - mace: 14.7927  
Epoch 00156: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 112ms/step - loss: 0.5001 - mse: 0.1385 - mace: 14.7931 - val_loss: 0.7958 - val_mse: 0.3584 - val_mace: 24.2531
Epoch 157/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5015 - mse: 0.1392 - mace: 14.8393  
Epoch 00157: val_loss did not improve from 0.72006
1016/1016 [==============================] - 123s 121ms/step - loss: 0.5015 - mse: 0.1392 - mace: 14.8403 - val_loss: 0.7761 - val_mse: 0.3403 - val_mace: 23.6377
Epoch 158/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5019 - mse: 0.1394 - mace: 14.8575  
Epoch 00158: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 116ms/step - loss: 0.5018 - mse: 0.1394 - mace: 14.8562 - val_loss: 0.8428 - val_mse: 0.4020 - val_mace: 25.7479
Epoch 159/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5041 - mse: 0.1405 - mace: 14.9169  
Epoch 00159: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 117ms/step - loss: 0.5041 - mse: 0.1404 - mace: 14.9159 - val_loss: 0.8433 - val_mse: 0.4014 - val_mace: 25.7806
Epoch 160/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5037 - mse: 0.1402 - mace: 14.9052  
Epoch 00160: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5038 - mse: 0.1402 - mace: 14.9058 - val_loss: 0.8060 - val_mse: 0.3664 - val_mace: 24.5733
Epoch 161/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4986 - mse: 0.1376 - mace: 14.7392  
Epoch 00161: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.4986 - mse: 0.1376 - mace: 14.7386 - val_loss: 0.8644 - val_mse: 0.4209 - val_mace: 26.4434
Epoch 162/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4899 - mse: 0.1328 - mace: 14.4588  
Epoch 00162: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.4899 - mse: 0.1328 - mace: 14.4584 - val_loss: 0.8617 - val_mse: 0.4184 - val_mace: 26.3544
Epoch 163/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4927 - mse: 0.1342 - mace: 14.5412  
Epoch 00163: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.4926 - mse: 0.1341 - mace: 14.5407 - val_loss: 0.8054 - val_mse: 0.3642 - val_mace: 24.5484
Epoch 164/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4968 - mse: 0.1361 - mace: 14.6710  
Epoch 00164: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 117ms/step - loss: 0.4967 - mse: 0.1361 - mace: 14.6703 - val_loss: 0.7939 - val_mse: 0.3559 - val_mace: 24.1761
Epoch 165/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4979 - mse: 0.1370 - mace: 14.7095  
Epoch 00165: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.4979 - mse: 0.1370 - mace: 14.7102 - val_loss: 0.7970 - val_mse: 0.3590 - val_mace: 24.2793
Epoch 166/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4967 - mse: 0.1364 - mace: 14.6749  
Epoch 00166: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.4968 - mse: 0.1365 - mace: 14.6761 - val_loss: 0.7897 - val_mse: 0.3516 - val_mace: 24.0588
Epoch 167/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4976 - mse: 0.1365 - mace: 14.6903  
Epoch 00167: val_loss did not improve from 0.72006
1016/1016 [==============================] - 112s 110ms/step - loss: 0.4975 - mse: 0.1365 - mace: 14.6888 - val_loss: 0.7441 - val_mse: 0.3113 - val_mace: 22.5721
Epoch 168/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4995 - mse: 0.1378 - mace: 14.7572   
Epoch 00168: val_loss did not improve from 0.72006
1016/1016 [==============================] - 127s 125ms/step - loss: 0.4995 - mse: 0.1378 - mace: 14.7574 - val_loss: 0.7591 - val_mse: 0.3252 - val_mace: 23.0931
Epoch 169/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5006 - mse: 0.1386 - mace: 14.8042  
Epoch 00169: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 112ms/step - loss: 0.5006 - mse: 0.1386 - mace: 14.8047 - val_loss: 0.7585 - val_mse: 0.3232 - val_mace: 23.0679
Epoch 170/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.5008 - mse: 0.1386 - mace: 14.8191  
Epoch 00170: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.5008 - mse: 0.1386 - mace: 14.8184 - val_loss: 0.7996 - val_mse: 0.3616 - val_mace: 24.3858
Epoch 171/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4921 - mse: 0.1343 - mace: 14.5380  
Epoch 00171: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.4922 - mse: 0.1343 - mace: 14.5387 - val_loss: 0.8023 - val_mse: 0.3623 - val_mace: 24.4604
Epoch 172/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4889 - mse: 0.1323 - mace: 14.4250  
Epoch 00172: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 115ms/step - loss: 0.4889 - mse: 0.1323 - mace: 14.4252 - val_loss: 0.8094 - val_mse: 0.3691 - val_mace: 24.6727
Epoch 173/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4904 - mse: 0.1328 - mace: 14.4664  
Epoch 00173: val_loss did not improve from 0.72006
1016/1016 [==============================] - 105s 103ms/step - loss: 0.4904 - mse: 0.1328 - mace: 14.4660 - val_loss: 0.7496 - val_mse: 0.3165 - val_mace: 22.7584
Epoch 174/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4907 - mse: 0.1327 - mace: 14.4714  
Epoch 00174: val_loss did not improve from 0.72006
1016/1016 [==============================] - 125s 123ms/step - loss: 0.4907 - mse: 0.1327 - mace: 14.4721 - val_loss: 0.7581 - val_mse: 0.3242 - val_mace: 23.0241
Epoch 175/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4945 - mse: 0.1346 - mace: 14.5793  
Epoch 00175: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.4945 - mse: 0.1346 - mace: 14.5791 - val_loss: 0.7956 - val_mse: 0.3573 - val_mace: 24.2191
Epoch 176/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4949 - mse: 0.1352 - mace: 14.6087  
Epoch 00176: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 115ms/step - loss: 0.4949 - mse: 0.1352 - mace: 14.6086 - val_loss: 0.7488 - val_mse: 0.3150 - val_mace: 22.7462
Epoch 177/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4946 - mse: 0.1348 - mace: 14.5868  
Epoch 00177: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 114ms/step - loss: 0.4946 - mse: 0.1348 - mace: 14.5881 - val_loss: 0.7994 - val_mse: 0.3594 - val_mace: 24.3166
Epoch 178/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4966 - mse: 0.1360 - mace: 14.6602  
Epoch 00178: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.4966 - mse: 0.1361 - mace: 14.6609 - val_loss: 0.7743 - val_mse: 0.3380 - val_mace: 23.5565
Epoch 179/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4983 - mse: 0.1373 - mace: 14.7333  
Epoch 00179: val_loss did not improve from 0.72006
1016/1016 [==============================] - 106s 104ms/step - loss: 0.4984 - mse: 0.1374 - mace: 14.7352 - val_loss: 0.7951 - val_mse: 0.3569 - val_mace: 24.2403
Epoch 180/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4974 - mse: 0.1368 - mace: 14.7070  
Epoch 00180: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.4974 - mse: 0.1368 - mace: 14.7062 - val_loss: 0.7726 - val_mse: 0.3395 - val_mace: 23.5133
Epoch 181/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4916 - mse: 0.1336 - mace: 14.5113  
Epoch 00181: val_loss did not improve from 0.72006
1016/1016 [==============================] - 114s 112ms/step - loss: 0.4916 - mse: 0.1336 - mace: 14.5108 - val_loss: 0.7682 - val_mse: 0.3315 - val_mace: 23.3530
Epoch 182/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4841 - mse: 0.1293 - mace: 14.2540  
Epoch 00182: val_loss did not improve from 0.72006
1016/1016 [==============================] - 126s 124ms/step - loss: 0.4841 - mse: 0.1293 - mace: 14.2538 - val_loss: 0.7565 - val_mse: 0.3207 - val_mace: 22.9581
Epoch 183/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4868 - mse: 0.1309 - mace: 14.3444  
Epoch 00183: val_loss did not improve from 0.72006
1016/1016 [==============================] - 113s 111ms/step - loss: 0.4868 - mse: 0.1309 - mace: 14.3442 - val_loss: 0.8149 - val_mse: 0.3752 - val_mace: 24.8348
Epoch 184/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4888 - mse: 0.1317 - mace: 14.4061  
Epoch 00184: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.4887 - mse: 0.1317 - mace: 14.4052 - val_loss: 0.7973 - val_mse: 0.3581 - val_mace: 24.2729
Epoch 185/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4881 - mse: 0.1316 - mace: 14.3865  
Epoch 00185: val_loss did not improve from 0.72006
1016/1016 [==============================] - 107s 105ms/step - loss: 0.4881 - mse: 0.1316 - mace: 14.3870 - val_loss: 0.8087 - val_mse: 0.3711 - val_mace: 24.6565
Epoch 186/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4931 - mse: 0.1342 - mace: 14.5505  
Epoch 00186: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 115ms/step - loss: 0.4932 - mse: 0.1342 - mace: 14.5521 - val_loss: 0.8020 - val_mse: 0.3634 - val_mace: 24.4287
Epoch 187/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4947 - mse: 0.1351 - mace: 14.6034  
Epoch 00187: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.4947 - mse: 0.1351 - mace: 14.6035 - val_loss: 0.8162 - val_mse: 0.3757 - val_mace: 24.8963
Epoch 188/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4941 - mse: 0.1346 - mace: 14.5722  
Epoch 00188: val_loss did not improve from 0.72006
1016/1016 [==============================] - 127s 125ms/step - loss: 0.4941 - mse: 0.1346 - mace: 14.5722 - val_loss: 0.8361 - val_mse: 0.3937 - val_mace: 25.5077
Epoch 189/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4939 - mse: 0.1345 - mace: 14.5712  
Epoch 00189: val_loss did not improve from 0.72006
1016/1016 [==============================] - 115s 113ms/step - loss: 0.4939 - mse: 0.1345 - mace: 14.5718 - val_loss: 0.7976 - val_mse: 0.3583 - val_mace: 24.2904
Epoch 190/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4960 - mse: 0.1355 - mace: 14.6237  
Epoch 00190: val_loss did not improve from 0.72006
1016/1016 [==============================] - 109s 108ms/step - loss: 0.4960 - mse: 0.1355 - mace: 14.6226 - val_loss: 0.8353 - val_mse: 0.3931 - val_mace: 25.4838
Epoch 191/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4852 - mse: 0.1300 - mace: 14.2951  
Epoch 00191: val_loss did not improve from 0.72006
1016/1016 [==============================] - 117s 116ms/step - loss: 0.4852 - mse: 0.1300 - mace: 14.2951 - val_loss: 0.8166 - val_mse: 0.3763 - val_mace: 24.8928
Epoch 192/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4860 - mse: 0.1302 - mace: 14.3120  
Epoch 00192: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 121ms/step - loss: 0.4861 - mse: 0.1302 - mace: 14.3125 - val_loss: 0.8079 - val_mse: 0.3681 - val_mace: 24.6145
Epoch 193/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4893 - mse: 0.1320 - mace: 14.4179  
Epoch 00193: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 115ms/step - loss: 0.4893 - mse: 0.1320 - mace: 14.4183 - val_loss: 0.7869 - val_mse: 0.3491 - val_mace: 23.9500
Epoch 194/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4837 - mse: 0.1291 - mace: 14.2434  
Epoch 00194: val_loss did not improve from 0.72006
1016/1016 [==============================] - 122s 120ms/step - loss: 0.4837 - mse: 0.1291 - mace: 14.2434 - val_loss: 0.8447 - val_mse: 0.4028 - val_mace: 25.7824
Epoch 195/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4857 - mse: 0.1300 - mace: 14.3074  
Epoch 00195: val_loss did not improve from 0.72006
1016/1016 [==============================] - 116s 115ms/step - loss: 0.4857 - mse: 0.1300 - mace: 14.3069 - val_loss: 0.7769 - val_mse: 0.3404 - val_mace: 23.6394
Epoch 196/196
1015/1016 [============================>.] - ETA: 0s - loss: 0.4891 - mse: 0.1321 - mace: 14.4299  
Epoch 00196: val_loss did not improve from 0.72006
1016/1016 [==============================] - 118s 116ms/step - loss: 0.4891 - mse: 0.1321 - mace: 14.4285 - val_loss: 0.7622 - val_mse: 0.3263 - val_mace: 23.1721
------------- end -------------

real	386m0.720s
user	321m26.338s
sys	18m44.483s