python train_transfer_learning.py 
2019-03-14 06:32:36.023658: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-03-14 06:32:36.029552: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-03-14 06:32:36.151180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1009] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-03-14 06:32:36.151938: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x56dd3e0 executing computations on platform CUDA. Devices:
2019-03-14 06:32:36.151960: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): GeForce RTX 2060, Compute Capability 7.5
2019-03-14 06:32:36.172043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3192000000 Hz
2019-03-14 06:32:36.172530: I tensorflow/compiler/xla/service/service.cc:162] XLA service 0x5749d50 executing computations on platform Host. Devices:
2019-03-14 06:32:36.172682: I tensorflow/compiler/xla/service/service.cc:169]   StreamExecutor device (0): <undefined>, <undefined>
2019-03-14 06:32:36.173086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1467] Found device 0 with properties: 
name: GeForce RTX 2060 major: 7 minor: 5 memoryClockRate(GHz): 1.83
pciBusID: 0000:01:00.0
totalMemory: 5.76GiB freeMemory: 5.43GiB
2019-03-14 06:32:36.173119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-14 06:32:36.173180: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-03-14 06:32:36.174172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 06:32:36.174199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-14 06:32:36.174213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-14 06:32:36.174421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5248 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2019-03-14 06:32:36.188354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1546] Adding visible gpu devices: 0
2019-03-14 06:32:36.188402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1015] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-14 06:32:36.188411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1021]      0 
2019-03-14 06:32:36.188419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1034] 0:   N 
2019-03-14 06:32:36.188557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1149] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5248 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            [(None, 128, 128, 3) 0                                            
__________________________________________________________________________________________________
Conv1_pad_1 (ZeroPadding2D)     (None, 129, 129, 3)  0           input_2[0][0]                    
__________________________________________________________________________________________________
Conv1_pad_2 (ZeroPadding2D)     (None, 129, 129, 3)  0           input_4[0][0]                    
__________________________________________________________________________________________________
Conv1_1 (Conv2D)                (None, 64, 64, 32)   864         Conv1_pad_1[0][0]                
__________________________________________________________________________________________________
Conv1_2 (Conv2D)                (None, 64, 64, 32)   864         Conv1_pad_2[0][0]                
__________________________________________________________________________________________________
bn_Conv1_1 (BatchNormalizationV (None, 64, 64, 32)   128         Conv1_1[0][0]                    
__________________________________________________________________________________________________
bn_Conv1_2 (BatchNormalizationV (None, 64, 64, 32)   128         Conv1_2[0][0]                    
__________________________________________________________________________________________________
Conv1_relu_1 (ReLU)             (None, 64, 64, 32)   0           bn_Conv1_1[0][0]                 
__________________________________________________________________________________________________
Conv1_relu_2 (ReLU)             (None, 64, 64, 32)   0           bn_Conv1_2[0][0]                 
__________________________________________________________________________________________________
expanded_conv_depthwise_1 (Dept (None, 64, 64, 32)   288         Conv1_relu_1[0][0]               
__________________________________________________________________________________________________
expanded_conv_depthwise_2 (Dept (None, 64, 64, 32)   288         Conv1_relu_2[0][0]               
__________________________________________________________________________________________________
expanded_conv_depthwise_BN_1 (B (None, 64, 64, 32)   128         expanded_conv_depthwise_1[0][0]  
__________________________________________________________________________________________________
expanded_conv_depthwise_BN_2 (B (None, 64, 64, 32)   128         expanded_conv_depthwise_2[0][0]  
__________________________________________________________________________________________________
expanded_conv_depthwise_relu_1  (None, 64, 64, 32)   0           expanded_conv_depthwise_BN_1[0][0
__________________________________________________________________________________________________
expanded_conv_depthwise_relu_2  (None, 64, 64, 32)   0           expanded_conv_depthwise_BN_2[0][0
__________________________________________________________________________________________________
expanded_conv_project_1 (Conv2D (None, 64, 64, 16)   512         expanded_conv_depthwise_relu_1[0]
__________________________________________________________________________________________________
expanded_conv_project_2 (Conv2D (None, 64, 64, 16)   512         expanded_conv_depthwise_relu_2[0]
__________________________________________________________________________________________________
expanded_conv_project_BN_1 (Bat (None, 64, 64, 16)   64          expanded_conv_project_1[0][0]    
__________________________________________________________________________________________________
expanded_conv_project_BN_2 (Bat (None, 64, 64, 16)   64          expanded_conv_project_2[0][0]    
__________________________________________________________________________________________________
block_1_expand_1 (Conv2D)       (None, 64, 64, 96)   1536        expanded_conv_project_BN_1[0][0] 
__________________________________________________________________________________________________
block_1_expand_2 (Conv2D)       (None, 64, 64, 96)   1536        expanded_conv_project_BN_2[0][0] 
__________________________________________________________________________________________________
block_1_expand_BN_1 (BatchNorma (None, 64, 64, 96)   384         block_1_expand_1[0][0]           
__________________________________________________________________________________________________
block_1_expand_BN_2 (BatchNorma (None, 64, 64, 96)   384         block_1_expand_2[0][0]           
__________________________________________________________________________________________________
block_1_expand_relu_1 (ReLU)    (None, 64, 64, 96)   0           block_1_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_1_expand_relu_2 (ReLU)    (None, 64, 64, 96)   0           block_1_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_1_pad_1 (ZeroPadding2D)   (None, 65, 65, 96)   0           block_1_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_1_pad_2 (ZeroPadding2D)   (None, 65, 65, 96)   0           block_1_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_1_depthwise_1 (DepthwiseC (None, 32, 32, 96)   864         block_1_pad_1[0][0]              
__________________________________________________________________________________________________
block_1_depthwise_2 (DepthwiseC (None, 32, 32, 96)   864         block_1_pad_2[0][0]              
__________________________________________________________________________________________________
block_1_depthwise_BN_1 (BatchNo (None, 32, 32, 96)   384         block_1_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_1_depthwise_BN_2 (BatchNo (None, 32, 32, 96)   384         block_1_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_1_depthwise_relu_1 (ReLU) (None, 32, 32, 96)   0           block_1_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_1_depthwise_relu_2 (ReLU) (None, 32, 32, 96)   0           block_1_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_1_project_1 (Conv2D)      (None, 32, 32, 24)   2304        block_1_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_1_project_2 (Conv2D)      (None, 32, 32, 24)   2304        block_1_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_1_project_BN_1 (BatchNorm (None, 32, 32, 24)   96          block_1_project_1[0][0]          
__________________________________________________________________________________________________
block_1_project_BN_2 (BatchNorm (None, 32, 32, 24)   96          block_1_project_2[0][0]          
__________________________________________________________________________________________________
block_2_expand_1 (Conv2D)       (None, 32, 32, 144)  3456        block_1_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_2_expand_2 (Conv2D)       (None, 32, 32, 144)  3456        block_1_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_2_expand_BN_1 (BatchNorma (None, 32, 32, 144)  576         block_2_expand_1[0][0]           
__________________________________________________________________________________________________
block_2_expand_BN_2 (BatchNorma (None, 32, 32, 144)  576         block_2_expand_2[0][0]           
__________________________________________________________________________________________________
block_2_expand_relu_1 (ReLU)    (None, 32, 32, 144)  0           block_2_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_2_expand_relu_2 (ReLU)    (None, 32, 32, 144)  0           block_2_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_1 (DepthwiseC (None, 32, 32, 144)  1296        block_2_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_2_depthwise_2 (DepthwiseC (None, 32, 32, 144)  1296        block_2_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_2_depthwise_BN_1 (BatchNo (None, 32, 32, 144)  576         block_2_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_BN_2 (BatchNo (None, 32, 32, 144)  576         block_2_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_2_depthwise_relu_1 (ReLU) (None, 32, 32, 144)  0           block_2_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_2_depthwise_relu_2 (ReLU) (None, 32, 32, 144)  0           block_2_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_2_project_1 (Conv2D)      (None, 32, 32, 24)   3456        block_2_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_2_project_2 (Conv2D)      (None, 32, 32, 24)   3456        block_2_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_2_project_BN_1 (BatchNorm (None, 32, 32, 24)   96          block_2_project_1[0][0]          
__________________________________________________________________________________________________
block_2_project_BN_2 (BatchNorm (None, 32, 32, 24)   96          block_2_project_2[0][0]          
__________________________________________________________________________________________________
block_2_add_1 (Add)             (None, 32, 32, 24)   0           block_1_project_BN_1[0][0]       
                                                                 block_2_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_2_add_2 (Add)             (None, 32, 32, 24)   0           block_1_project_BN_2[0][0]       
                                                                 block_2_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_3_expand_1 (Conv2D)       (None, 32, 32, 144)  3456        block_2_add_1[0][0]              
__________________________________________________________________________________________________
block_3_expand_2 (Conv2D)       (None, 32, 32, 144)  3456        block_2_add_2[0][0]              
__________________________________________________________________________________________________
block_3_expand_BN_1 (BatchNorma (None, 32, 32, 144)  576         block_3_expand_1[0][0]           
__________________________________________________________________________________________________
block_3_expand_BN_2 (BatchNorma (None, 32, 32, 144)  576         block_3_expand_2[0][0]           
__________________________________________________________________________________________________
block_3_expand_relu_1 (ReLU)    (None, 32, 32, 144)  0           block_3_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_3_expand_relu_2 (ReLU)    (None, 32, 32, 144)  0           block_3_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_3_pad_1 (ZeroPadding2D)   (None, 33, 33, 144)  0           block_3_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_3_pad_2 (ZeroPadding2D)   (None, 33, 33, 144)  0           block_3_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_3_depthwise_1 (DepthwiseC (None, 16, 16, 144)  1296        block_3_pad_1[0][0]              
__________________________________________________________________________________________________
block_3_depthwise_2 (DepthwiseC (None, 16, 16, 144)  1296        block_3_pad_2[0][0]              
__________________________________________________________________________________________________
block_3_depthwise_BN_1 (BatchNo (None, 16, 16, 144)  576         block_3_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_3_depthwise_BN_2 (BatchNo (None, 16, 16, 144)  576         block_3_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_3_depthwise_relu_1 (ReLU) (None, 16, 16, 144)  0           block_3_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_3_depthwise_relu_2 (ReLU) (None, 16, 16, 144)  0           block_3_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_3_project_1 (Conv2D)      (None, 16, 16, 32)   4608        block_3_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_3_project_2 (Conv2D)      (None, 16, 16, 32)   4608        block_3_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_3_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_3_project_1[0][0]          
__________________________________________________________________________________________________
block_3_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_3_project_2[0][0]          
__________________________________________________________________________________________________
block_4_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_3_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_4_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_3_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_4_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_4_expand_1[0][0]           
__________________________________________________________________________________________________
block_4_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_4_expand_2[0][0]           
__________________________________________________________________________________________________
block_4_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_4_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_4_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_4_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_1 (DepthwiseC (None, 16, 16, 192)  1728        block_4_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_4_depthwise_2 (DepthwiseC (None, 16, 16, 192)  1728        block_4_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_4_depthwise_BN_1 (BatchNo (None, 16, 16, 192)  768         block_4_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_BN_2 (BatchNo (None, 16, 16, 192)  768         block_4_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_4_depthwise_relu_1 (ReLU) (None, 16, 16, 192)  0           block_4_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_4_depthwise_relu_2 (ReLU) (None, 16, 16, 192)  0           block_4_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_4_project_1 (Conv2D)      (None, 16, 16, 32)   6144        block_4_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_4_project_2 (Conv2D)      (None, 16, 16, 32)   6144        block_4_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_4_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_4_project_1[0][0]          
__________________________________________________________________________________________________
block_4_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_4_project_2[0][0]          
__________________________________________________________________________________________________
block_4_add_1 (Add)             (None, 16, 16, 32)   0           block_3_project_BN_1[0][0]       
                                                                 block_4_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_4_add_2 (Add)             (None, 16, 16, 32)   0           block_3_project_BN_2[0][0]       
                                                                 block_4_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_5_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_4_add_1[0][0]              
__________________________________________________________________________________________________
block_5_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_4_add_2[0][0]              
__________________________________________________________________________________________________
block_5_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_5_expand_1[0][0]           
__________________________________________________________________________________________________
block_5_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_5_expand_2[0][0]           
__________________________________________________________________________________________________
block_5_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_5_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_5_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_5_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_1 (DepthwiseC (None, 16, 16, 192)  1728        block_5_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_5_depthwise_2 (DepthwiseC (None, 16, 16, 192)  1728        block_5_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_5_depthwise_BN_1 (BatchNo (None, 16, 16, 192)  768         block_5_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_BN_2 (BatchNo (None, 16, 16, 192)  768         block_5_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_5_depthwise_relu_1 (ReLU) (None, 16, 16, 192)  0           block_5_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_5_depthwise_relu_2 (ReLU) (None, 16, 16, 192)  0           block_5_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_5_project_1 (Conv2D)      (None, 16, 16, 32)   6144        block_5_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_5_project_2 (Conv2D)      (None, 16, 16, 32)   6144        block_5_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_5_project_BN_1 (BatchNorm (None, 16, 16, 32)   128         block_5_project_1[0][0]          
__________________________________________________________________________________________________
block_5_project_BN_2 (BatchNorm (None, 16, 16, 32)   128         block_5_project_2[0][0]          
__________________________________________________________________________________________________
block_5_add_1 (Add)             (None, 16, 16, 32)   0           block_4_add_1[0][0]              
                                                                 block_5_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_5_add_2 (Add)             (None, 16, 16, 32)   0           block_4_add_2[0][0]              
                                                                 block_5_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_6_expand_1 (Conv2D)       (None, 16, 16, 192)  6144        block_5_add_1[0][0]              
__________________________________________________________________________________________________
block_6_expand_2 (Conv2D)       (None, 16, 16, 192)  6144        block_5_add_2[0][0]              
__________________________________________________________________________________________________
block_6_expand_BN_1 (BatchNorma (None, 16, 16, 192)  768         block_6_expand_1[0][0]           
__________________________________________________________________________________________________
block_6_expand_BN_2 (BatchNorma (None, 16, 16, 192)  768         block_6_expand_2[0][0]           
__________________________________________________________________________________________________
block_6_expand_relu_1 (ReLU)    (None, 16, 16, 192)  0           block_6_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_6_expand_relu_2 (ReLU)    (None, 16, 16, 192)  0           block_6_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_6_pad_1 (ZeroPadding2D)   (None, 17, 17, 192)  0           block_6_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_6_pad_2 (ZeroPadding2D)   (None, 17, 17, 192)  0           block_6_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_6_depthwise_1 (DepthwiseC (None, 8, 8, 192)    1728        block_6_pad_1[0][0]              
__________________________________________________________________________________________________
block_6_depthwise_2 (DepthwiseC (None, 8, 8, 192)    1728        block_6_pad_2[0][0]              
__________________________________________________________________________________________________
block_6_depthwise_BN_1 (BatchNo (None, 8, 8, 192)    768         block_6_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_6_depthwise_BN_2 (BatchNo (None, 8, 8, 192)    768         block_6_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_6_depthwise_relu_1 (ReLU) (None, 8, 8, 192)    0           block_6_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_6_depthwise_relu_2 (ReLU) (None, 8, 8, 192)    0           block_6_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_6_project_1 (Conv2D)      (None, 8, 8, 64)     12288       block_6_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_6_project_2 (Conv2D)      (None, 8, 8, 64)     12288       block_6_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_6_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_6_project_1[0][0]          
__________________________________________________________________________________________________
block_6_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_6_project_2[0][0]          
__________________________________________________________________________________________________
block_7_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_6_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_7_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_6_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_7_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_7_expand_1[0][0]           
__________________________________________________________________________________________________
block_7_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_7_expand_2[0][0]           
__________________________________________________________________________________________________
block_7_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_7_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_7_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_7_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_7_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_7_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_7_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_7_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_7_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_7_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_7_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_7_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_7_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_7_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_7_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_7_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_7_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_7_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_7_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_7_project_1[0][0]          
__________________________________________________________________________________________________
block_7_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_7_project_2[0][0]          
__________________________________________________________________________________________________
block_7_add_1 (Add)             (None, 8, 8, 64)     0           block_6_project_BN_1[0][0]       
                                                                 block_7_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_7_add_2 (Add)             (None, 8, 8, 64)     0           block_6_project_BN_2[0][0]       
                                                                 block_7_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_8_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_7_add_1[0][0]              
__________________________________________________________________________________________________
block_8_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_7_add_2[0][0]              
__________________________________________________________________________________________________
block_8_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_8_expand_1[0][0]           
__________________________________________________________________________________________________
block_8_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_8_expand_2[0][0]           
__________________________________________________________________________________________________
block_8_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_8_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_8_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_8_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_8_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_8_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_8_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_8_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_8_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_8_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_8_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_8_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_8_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_8_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_8_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_8_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_8_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_8_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_8_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_8_project_1[0][0]          
__________________________________________________________________________________________________
block_8_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_8_project_2[0][0]          
__________________________________________________________________________________________________
block_8_add_1 (Add)             (None, 8, 8, 64)     0           block_7_add_1[0][0]              
                                                                 block_8_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_8_add_2 (Add)             (None, 8, 8, 64)     0           block_7_add_2[0][0]              
                                                                 block_8_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_9_expand_1 (Conv2D)       (None, 8, 8, 384)    24576       block_8_add_1[0][0]              
__________________________________________________________________________________________________
block_9_expand_2 (Conv2D)       (None, 8, 8, 384)    24576       block_8_add_2[0][0]              
__________________________________________________________________________________________________
block_9_expand_BN_1 (BatchNorma (None, 8, 8, 384)    1536        block_9_expand_1[0][0]           
__________________________________________________________________________________________________
block_9_expand_BN_2 (BatchNorma (None, 8, 8, 384)    1536        block_9_expand_2[0][0]           
__________________________________________________________________________________________________
block_9_expand_relu_1 (ReLU)    (None, 8, 8, 384)    0           block_9_expand_BN_1[0][0]        
__________________________________________________________________________________________________
block_9_expand_relu_2 (ReLU)    (None, 8, 8, 384)    0           block_9_expand_BN_2[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_1 (DepthwiseC (None, 8, 8, 384)    3456        block_9_expand_relu_1[0][0]      
__________________________________________________________________________________________________
block_9_depthwise_2 (DepthwiseC (None, 8, 8, 384)    3456        block_9_expand_relu_2[0][0]      
__________________________________________________________________________________________________
block_9_depthwise_BN_1 (BatchNo (None, 8, 8, 384)    1536        block_9_depthwise_1[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_BN_2 (BatchNo (None, 8, 8, 384)    1536        block_9_depthwise_2[0][0]        
__________________________________________________________________________________________________
block_9_depthwise_relu_1 (ReLU) (None, 8, 8, 384)    0           block_9_depthwise_BN_1[0][0]     
__________________________________________________________________________________________________
block_9_depthwise_relu_2 (ReLU) (None, 8, 8, 384)    0           block_9_depthwise_BN_2[0][0]     
__________________________________________________________________________________________________
block_9_project_1 (Conv2D)      (None, 8, 8, 64)     24576       block_9_depthwise_relu_1[0][0]   
__________________________________________________________________________________________________
block_9_project_2 (Conv2D)      (None, 8, 8, 64)     24576       block_9_depthwise_relu_2[0][0]   
__________________________________________________________________________________________________
block_9_project_BN_1 (BatchNorm (None, 8, 8, 64)     256         block_9_project_1[0][0]          
__________________________________________________________________________________________________
block_9_project_BN_2 (BatchNorm (None, 8, 8, 64)     256         block_9_project_2[0][0]          
__________________________________________________________________________________________________
block_9_add_1 (Add)             (None, 8, 8, 64)     0           block_8_add_1[0][0]              
                                                                 block_9_project_BN_1[0][0]       
__________________________________________________________________________________________________
block_9_add_2 (Add)             (None, 8, 8, 64)     0           block_8_add_2[0][0]              
                                                                 block_9_project_BN_2[0][0]       
__________________________________________________________________________________________________
block_10_expand_1 (Conv2D)      (None, 8, 8, 384)    24576       block_9_add_1[0][0]              
__________________________________________________________________________________________________
block_10_expand_2 (Conv2D)      (None, 8, 8, 384)    24576       block_9_add_2[0][0]              
__________________________________________________________________________________________________
block_10_expand_BN_1 (BatchNorm (None, 8, 8, 384)    1536        block_10_expand_1[0][0]          
__________________________________________________________________________________________________
block_10_expand_BN_2 (BatchNorm (None, 8, 8, 384)    1536        block_10_expand_2[0][0]          
__________________________________________________________________________________________________
block_10_expand_relu_1 (ReLU)   (None, 8, 8, 384)    0           block_10_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_10_expand_relu_2 (ReLU)   (None, 8, 8, 384)    0           block_10_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_1 (Depthwise (None, 8, 8, 384)    3456        block_10_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_10_depthwise_2 (Depthwise (None, 8, 8, 384)    3456        block_10_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_10_depthwise_BN_1 (BatchN (None, 8, 8, 384)    1536        block_10_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_BN_2 (BatchN (None, 8, 8, 384)    1536        block_10_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_10_depthwise_relu_1 (ReLU (None, 8, 8, 384)    0           block_10_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_10_depthwise_relu_2 (ReLU (None, 8, 8, 384)    0           block_10_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_10_project_1 (Conv2D)     (None, 8, 8, 96)     36864       block_10_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_10_project_2 (Conv2D)     (None, 8, 8, 96)     36864       block_10_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_10_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_10_project_1[0][0]         
__________________________________________________________________________________________________
block_10_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_10_project_2[0][0]         
__________________________________________________________________________________________________
block_11_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_10_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_11_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_10_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_11_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_11_expand_1[0][0]          
__________________________________________________________________________________________________
block_11_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_11_expand_2[0][0]          
__________________________________________________________________________________________________
block_11_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_11_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_11_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_11_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_1 (Depthwise (None, 8, 8, 576)    5184        block_11_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_11_depthwise_2 (Depthwise (None, 8, 8, 576)    5184        block_11_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_11_depthwise_BN_1 (BatchN (None, 8, 8, 576)    2304        block_11_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_BN_2 (BatchN (None, 8, 8, 576)    2304        block_11_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_11_depthwise_relu_1 (ReLU (None, 8, 8, 576)    0           block_11_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_11_depthwise_relu_2 (ReLU (None, 8, 8, 576)    0           block_11_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_11_project_1 (Conv2D)     (None, 8, 8, 96)     55296       block_11_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_11_project_2 (Conv2D)     (None, 8, 8, 96)     55296       block_11_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_11_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_11_project_1[0][0]         
__________________________________________________________________________________________________
block_11_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_11_project_2[0][0]         
__________________________________________________________________________________________________
block_11_add_1 (Add)            (None, 8, 8, 96)     0           block_10_project_BN_1[0][0]      
                                                                 block_11_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_11_add_2 (Add)            (None, 8, 8, 96)     0           block_10_project_BN_2[0][0]      
                                                                 block_11_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_12_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_11_add_1[0][0]             
__________________________________________________________________________________________________
block_12_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_11_add_2[0][0]             
__________________________________________________________________________________________________
block_12_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_12_expand_1[0][0]          
__________________________________________________________________________________________________
block_12_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_12_expand_2[0][0]          
__________________________________________________________________________________________________
block_12_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_12_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_12_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_12_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_1 (Depthwise (None, 8, 8, 576)    5184        block_12_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_12_depthwise_2 (Depthwise (None, 8, 8, 576)    5184        block_12_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_12_depthwise_BN_1 (BatchN (None, 8, 8, 576)    2304        block_12_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_BN_2 (BatchN (None, 8, 8, 576)    2304        block_12_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_12_depthwise_relu_1 (ReLU (None, 8, 8, 576)    0           block_12_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_12_depthwise_relu_2 (ReLU (None, 8, 8, 576)    0           block_12_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_12_project_1 (Conv2D)     (None, 8, 8, 96)     55296       block_12_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_12_project_2 (Conv2D)     (None, 8, 8, 96)     55296       block_12_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_12_project_BN_1 (BatchNor (None, 8, 8, 96)     384         block_12_project_1[0][0]         
__________________________________________________________________________________________________
block_12_project_BN_2 (BatchNor (None, 8, 8, 96)     384         block_12_project_2[0][0]         
__________________________________________________________________________________________________
block_12_add_1 (Add)            (None, 8, 8, 96)     0           block_11_add_1[0][0]             
                                                                 block_12_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_12_add_2 (Add)            (None, 8, 8, 96)     0           block_11_add_2[0][0]             
                                                                 block_12_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_13_expand_1 (Conv2D)      (None, 8, 8, 576)    55296       block_12_add_1[0][0]             
__________________________________________________________________________________________________
block_13_expand_2 (Conv2D)      (None, 8, 8, 576)    55296       block_12_add_2[0][0]             
__________________________________________________________________________________________________
block_13_expand_BN_1 (BatchNorm (None, 8, 8, 576)    2304        block_13_expand_1[0][0]          
__________________________________________________________________________________________________
block_13_expand_BN_2 (BatchNorm (None, 8, 8, 576)    2304        block_13_expand_2[0][0]          
__________________________________________________________________________________________________
block_13_expand_relu_1 (ReLU)   (None, 8, 8, 576)    0           block_13_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_13_expand_relu_2 (ReLU)   (None, 8, 8, 576)    0           block_13_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_13_pad_1 (ZeroPadding2D)  (None, 9, 9, 576)    0           block_13_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_13_pad_2 (ZeroPadding2D)  (None, 9, 9, 576)    0           block_13_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_13_depthwise_1 (Depthwise (None, 4, 4, 576)    5184        block_13_pad_1[0][0]             
__________________________________________________________________________________________________
block_13_depthwise_2 (Depthwise (None, 4, 4, 576)    5184        block_13_pad_2[0][0]             
__________________________________________________________________________________________________
block_13_depthwise_BN_1 (BatchN (None, 4, 4, 576)    2304        block_13_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_13_depthwise_BN_2 (BatchN (None, 4, 4, 576)    2304        block_13_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_13_depthwise_relu_1 (ReLU (None, 4, 4, 576)    0           block_13_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_13_depthwise_relu_2 (ReLU (None, 4, 4, 576)    0           block_13_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_13_project_1 (Conv2D)     (None, 4, 4, 160)    92160       block_13_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_13_project_2 (Conv2D)     (None, 4, 4, 160)    92160       block_13_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_13_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_13_project_1[0][0]         
__________________________________________________________________________________________________
block_13_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_13_project_2[0][0]         
__________________________________________________________________________________________________
block_14_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_13_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_14_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_13_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_14_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_14_expand_1[0][0]          
__________________________________________________________________________________________________
block_14_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_14_expand_2[0][0]          
__________________________________________________________________________________________________
block_14_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_14_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_14_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_14_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_14_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_14_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_14_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_14_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_14_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_14_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_14_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_14_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_14_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_14_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_14_project_1 (Conv2D)     (None, 4, 4, 160)    153600      block_14_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_14_project_2 (Conv2D)     (None, 4, 4, 160)    153600      block_14_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_14_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_14_project_1[0][0]         
__________________________________________________________________________________________________
block_14_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_14_project_2[0][0]         
__________________________________________________________________________________________________
block_14_add_1 (Add)            (None, 4, 4, 160)    0           block_13_project_BN_1[0][0]      
                                                                 block_14_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_14_add_2 (Add)            (None, 4, 4, 160)    0           block_13_project_BN_2[0][0]      
                                                                 block_14_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_15_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_14_add_1[0][0]             
__________________________________________________________________________________________________
block_15_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_14_add_2[0][0]             
__________________________________________________________________________________________________
block_15_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_15_expand_1[0][0]          
__________________________________________________________________________________________________
block_15_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_15_expand_2[0][0]          
__________________________________________________________________________________________________
block_15_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_15_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_15_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_15_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_15_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_15_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_15_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_15_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_15_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_15_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_15_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_15_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_15_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_15_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_15_project_1 (Conv2D)     (None, 4, 4, 160)    153600      block_15_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_15_project_2 (Conv2D)     (None, 4, 4, 160)    153600      block_15_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_15_project_BN_1 (BatchNor (None, 4, 4, 160)    640         block_15_project_1[0][0]         
__________________________________________________________________________________________________
block_15_project_BN_2 (BatchNor (None, 4, 4, 160)    640         block_15_project_2[0][0]         
__________________________________________________________________________________________________
block_15_add_1 (Add)            (None, 4, 4, 160)    0           block_14_add_1[0][0]             
                                                                 block_15_project_BN_1[0][0]      
__________________________________________________________________________________________________
block_15_add_2 (Add)            (None, 4, 4, 160)    0           block_14_add_2[0][0]             
                                                                 block_15_project_BN_2[0][0]      
__________________________________________________________________________________________________
block_16_expand_1 (Conv2D)      (None, 4, 4, 960)    153600      block_15_add_1[0][0]             
__________________________________________________________________________________________________
block_16_expand_2 (Conv2D)      (None, 4, 4, 960)    153600      block_15_add_2[0][0]             
__________________________________________________________________________________________________
block_16_expand_BN_1 (BatchNorm (None, 4, 4, 960)    3840        block_16_expand_1[0][0]          
__________________________________________________________________________________________________
block_16_expand_BN_2 (BatchNorm (None, 4, 4, 960)    3840        block_16_expand_2[0][0]          
__________________________________________________________________________________________________
block_16_expand_relu_1 (ReLU)   (None, 4, 4, 960)    0           block_16_expand_BN_1[0][0]       
__________________________________________________________________________________________________
block_16_expand_relu_2 (ReLU)   (None, 4, 4, 960)    0           block_16_expand_BN_2[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_1 (Depthwise (None, 4, 4, 960)    8640        block_16_expand_relu_1[0][0]     
__________________________________________________________________________________________________
block_16_depthwise_2 (Depthwise (None, 4, 4, 960)    8640        block_16_expand_relu_2[0][0]     
__________________________________________________________________________________________________
block_16_depthwise_BN_1 (BatchN (None, 4, 4, 960)    3840        block_16_depthwise_1[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_BN_2 (BatchN (None, 4, 4, 960)    3840        block_16_depthwise_2[0][0]       
__________________________________________________________________________________________________
block_16_depthwise_relu_1 (ReLU (None, 4, 4, 960)    0           block_16_depthwise_BN_1[0][0]    
__________________________________________________________________________________________________
block_16_depthwise_relu_2 (ReLU (None, 4, 4, 960)    0           block_16_depthwise_BN_2[0][0]    
__________________________________________________________________________________________________
block_16_project_1 (Conv2D)     (None, 4, 4, 320)    307200      block_16_depthwise_relu_1[0][0]  
__________________________________________________________________________________________________
block_16_project_2 (Conv2D)     (None, 4, 4, 320)    307200      block_16_depthwise_relu_2[0][0]  
__________________________________________________________________________________________________
block_16_project_BN_1 (BatchNor (None, 4, 4, 320)    1280        block_16_project_1[0][0]         
__________________________________________________________________________________________________
block_16_project_BN_2 (BatchNor (None, 4, 4, 320)    1280        block_16_project_2[0][0]         
__________________________________________________________________________________________________
Conv_1_1 (Conv2D)               (None, 4, 4, 1280)   409600      block_16_project_BN_1[0][0]      
__________________________________________________________________________________________________
Conv_1_2 (Conv2D)               (None, 4, 4, 1280)   409600      block_16_project_BN_2[0][0]      
__________________________________________________________________________________________________
Conv_1_bn_1 (BatchNormalization (None, 4, 4, 1280)   5120        Conv_1_1[0][0]                   
__________________________________________________________________________________________________
Conv_1_bn_2 (BatchNormalization (None, 4, 4, 1280)   5120        Conv_1_2[0][0]                   
__________________________________________________________________________________________________
out_relu_1 (ReLU)               (None, 4, 4, 1280)   0           Conv_1_bn_1[0][0]                
__________________________________________________________________________________________________
out_relu_2 (ReLU)               (None, 4, 4, 1280)   0           Conv_1_bn_2[0][0]                
__________________________________________________________________________________________________
flatten (Flatten)               (None, 20480)        0           out_relu_1[0][0]                 
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 20480)        0           out_relu_2[0][0]                 
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 40960)        0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
fc2_2 (Dense)                   (None, 8)            327688      concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 8)            0           fc2_2[0][0]                      
__________________________________________________________________________________________________
fc1_2 (Dense)                   (None, 8)            72          dropout[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8)            0           fc1_2[0][0]                      
==================================================================================================
Total params: 4,843,728
Trainable params: 327,760
Non-trainable params: 4,515,968
__________________________________________________________________________________________________
None
------------- Training -------------
40670
8134
epochs: 98
epochs per stage: 24

Epoch 00001: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 1/98
2019-03-14 06:32:54.363697: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-03-14 06:32:54.583994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-03-14 06:32:55.735048: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profile Session started.
2019-03-14 06:32:55.764946: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcupti.so.10.0
   1/2033 [..............................] - ETA: 7:24:43 - loss: 2.2179 - mse: 6.1919 - mace: 70.9725WARNING: Logging before flag parsing goes to stderr.
W0314 06:32:56.136191 139635184113408 callbacks.py:236] Method (on_train_batch_end) is slow compared to the batch update (0.179160). Check your callbacks.
2032/2033 [============================>.] - ETA: 0s - loss: 0.7974 - mse: 0.7347 - mace: 25.5163       
Epoch 00001: val_loss improved from inf to 0.75990, saving model to checkpoint.h5
2033/2033 [==============================] - 129s 64ms/step - loss: 0.7973 - mse: 0.7344 - mace: 25.5144 - val_loss: 0.7599 - val_mse: 0.3292 - val_mace: 24.3169

Epoch 00002: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 2/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7655 - mse: 0.3336 - mace: 24.4972  
Epoch 00002: val_loss did not improve from 0.75990
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7655 - mse: 0.3336 - mace: 24.4975 - val_loss: 0.7687 - val_mse: 0.3359 - val_mace: 24.5995

Epoch 00003: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 3/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7663 - mse: 0.3343 - mace: 24.5226  
Epoch 00003: val_loss did not improve from 0.75990
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7663 - mse: 0.3342 - mace: 24.5218 - val_loss: 0.7647 - val_mse: 0.3329 - val_mace: 24.4691

Epoch 00004: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 4/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7658 - mse: 0.3337 - mace: 24.5055  
Epoch 00004: val_loss did not improve from 0.75990
2033/2033 [==============================] - 129s 63ms/step - loss: 0.7658 - mse: 0.3336 - mace: 24.5050 - val_loss: 0.7655 - val_mse: 0.3337 - val_mace: 24.4954

Epoch 00005: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 5/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7649 - mse: 0.3332 - mace: 24.4767  
Epoch 00005: val_loss did not improve from 0.75990
2033/2033 [==============================] - 114s 56ms/step - loss: 0.7649 - mse: 0.3331 - mace: 24.4754 - val_loss: 0.7635 - val_mse: 0.3320 - val_mace: 24.4324

Epoch 00006: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 6/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7663 - mse: 0.3343 - mace: 24.5202  
Epoch 00006: val_loss did not improve from 0.75990
2033/2033 [==============================] - 110s 54ms/step - loss: 0.7663 - mse: 0.3343 - mace: 24.5214 - val_loss: 0.7630 - val_mse: 0.3314 - val_mace: 24.4147

Epoch 00007: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 7/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7649 - mse: 0.3331 - mace: 24.4760   
Epoch 00007: val_loss did not improve from 0.75990
2033/2033 [==============================] - 129s 63ms/step - loss: 0.7649 - mse: 0.3331 - mace: 24.4760 - val_loss: 0.7663 - val_mse: 0.3340 - val_mace: 24.5227

Epoch 00008: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 8/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3330 - mace: 24.4693  
Epoch 00008: val_loss did not improve from 0.75990
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7647 - mse: 0.3331 - mace: 24.4696 - val_loss: 0.7679 - val_mse: 0.3357 - val_mace: 24.5736

Epoch 00009: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 9/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7640 - mse: 0.3325 - mace: 24.4472  
Epoch 00009: val_loss did not improve from 0.75990
2033/2033 [==============================] - 119s 58ms/step - loss: 0.7640 - mse: 0.3325 - mace: 24.4475 - val_loss: 0.7636 - val_mse: 0.3322 - val_mace: 24.4363

Epoch 00010: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 10/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7650 - mse: 0.3331 - mace: 24.4798  
Epoch 00010: val_loss did not improve from 0.75990
2033/2033 [==============================] - 117s 58ms/step - loss: 0.7650 - mse: 0.3331 - mace: 24.4797 - val_loss: 0.7633 - val_mse: 0.3315 - val_mace: 24.4250

Epoch 00011: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 11/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7657 - mse: 0.3338 - mace: 24.5012  
Epoch 00011: val_loss did not improve from 0.75990
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7657 - mse: 0.3338 - mace: 24.5015 - val_loss: 0.7646 - val_mse: 0.3327 - val_mace: 24.4682

Epoch 00012: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 12/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7707 - mse: 0.5780 - mace: 24.6614  
Epoch 00012: val_loss did not improve from 0.75990
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7707 - mse: 0.5777 - mace: 24.6619 - val_loss: 0.7639 - val_mse: 0.3321 - val_mace: 24.4461

Epoch 00013: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 13/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7662 - mse: 0.3340 - mace: 24.5170  
Epoch 00013: val_loss improved from 0.75990 to 0.75985, saving model to checkpoint.h5
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7662 - mse: 0.3340 - mace: 24.5182 - val_loss: 0.7598 - val_mse: 0.3291 - val_mace: 24.3152

Epoch 00014: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 14/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7649 - mse: 0.3330 - mace: 24.4771  
Epoch 00014: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7649 - mse: 0.3330 - mace: 24.4781 - val_loss: 0.7643 - val_mse: 0.3325 - val_mace: 24.4564

Epoch 00015: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 15/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7646 - mse: 0.3329 - mace: 24.4673  
Epoch 00015: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 58ms/step - loss: 0.7646 - mse: 0.3329 - mace: 24.4670 - val_loss: 0.7660 - val_mse: 0.3339 - val_mace: 24.5122

Epoch 00016: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 16/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7643 - mse: 0.3328 - mace: 24.4568  
Epoch 00016: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7643 - mse: 0.3328 - mace: 24.4561 - val_loss: 0.7640 - val_mse: 0.3325 - val_mace: 24.4483

Epoch 00017: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 17/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7667 - mse: 0.3346 - mace: 24.5344  
Epoch 00017: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7667 - mse: 0.3346 - mace: 24.5336 - val_loss: 0.7690 - val_mse: 0.3365 - val_mace: 24.6079

Epoch 00018: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 18/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7656 - mse: 0.3336 - mace: 24.5005  
Epoch 00018: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7657 - mse: 0.3336 - mace: 24.5016 - val_loss: 0.7654 - val_mse: 0.3335 - val_mace: 24.4943

Epoch 00019: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 19/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7638 - mse: 0.3324 - mace: 24.4421  
Epoch 00019: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 57ms/step - loss: 0.7638 - mse: 0.3324 - mace: 24.4424 - val_loss: 0.7678 - val_mse: 0.3357 - val_mace: 24.5707

Epoch 00020: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 20/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7653 - mse: 0.3334 - mace: 24.4899  
Epoch 00020: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7653 - mse: 0.3334 - mace: 24.4898 - val_loss: 0.7619 - val_mse: 0.3309 - val_mace: 24.3800

Epoch 00021: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 21/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7639 - mse: 0.3326 - mace: 24.4440  
Epoch 00021: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 58ms/step - loss: 0.7639 - mse: 0.3326 - mace: 24.4435 - val_loss: 0.7621 - val_mse: 0.3305 - val_mace: 24.3880

Epoch 00022: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 22/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7665 - mse: 0.3378 - mace: 24.5285  
Epoch 00022: val_loss did not improve from 0.75985
2033/2033 [==============================] - 109s 54ms/step - loss: 0.7665 - mse: 0.3378 - mace: 24.5287 - val_loss: 0.7624 - val_mse: 0.3311 - val_mace: 24.3972

Epoch 00023: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 23/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7657 - mse: 0.3335 - mace: 24.5037  
Epoch 00023: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7657 - mse: 0.3335 - mace: 24.5040 - val_loss: 0.7668 - val_mse: 0.3348 - val_mace: 24.5368

Epoch 00024: LearningRateScheduler reducing learning rate to 0.004999999888241291.
Epoch 24/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7654 - mse: 0.3334 - mace: 24.4926  
Epoch 00024: val_loss did not improve from 0.75985
2033/2033 [==============================] - 130s 64ms/step - loss: 0.7654 - mse: 0.3334 - mace: 24.4924 - val_loss: 0.7688 - val_mse: 0.3362 - val_mace: 24.6023

Epoch 00025: LearningRateScheduler reducing learning rate to 0.0004999999888241291.
Epoch 25/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7657 - mse: 0.3337 - mace: 24.5037  
Epoch 00025: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 58ms/step - loss: 0.7657 - mse: 0.3337 - mace: 24.5037 - val_loss: 0.7647 - val_mse: 0.3329 - val_mace: 24.4691

Epoch 00026: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 26/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7656 - mse: 0.3337 - mace: 24.4992  
Epoch 00026: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7656 - mse: 0.3337 - mace: 24.5001 - val_loss: 0.7655 - val_mse: 0.3337 - val_mace: 24.4954

Epoch 00027: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 27/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7633 - mse: 0.3320 - mace: 24.4252  
Epoch 00027: val_loss did not improve from 0.75985
2033/2033 [==============================] - 110s 54ms/step - loss: 0.7633 - mse: 0.3320 - mace: 24.4265 - val_loss: 0.7634 - val_mse: 0.3320 - val_mace: 24.4274

Epoch 00028: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 28/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7650 - mse: 0.3333 - mace: 24.4803  
Epoch 00028: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 58ms/step - loss: 0.7650 - mse: 0.3333 - mace: 24.4801 - val_loss: 0.7634 - val_mse: 0.3319 - val_mace: 24.4300

Epoch 00029: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 29/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7659 - mse: 0.3338 - mace: 24.5073  
Epoch 00029: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7658 - mse: 0.3338 - mace: 24.5065 - val_loss: 0.7669 - val_mse: 0.3343 - val_mace: 24.5418

Epoch 00030: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 30/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7655 - mse: 0.3338 - mace: 24.4955  
Epoch 00030: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7655 - mse: 0.3338 - mace: 24.4960 - val_loss: 0.7649 - val_mse: 0.3333 - val_mace: 24.4779

Epoch 00031: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 31/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7643 - mse: 0.3329 - mace: 24.4591   
Epoch 00031: val_loss did not improve from 0.75985
2033/2033 [==============================] - 122s 60ms/step - loss: 0.7643 - mse: 0.3329 - mace: 24.4590 - val_loss: 0.7660 - val_mse: 0.3336 - val_mace: 24.5132

Epoch 00032: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 32/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7645 - mse: 0.3327 - mace: 24.4656  
Epoch 00032: val_loss did not improve from 0.75985
2033/2033 [==============================] - 115s 56ms/step - loss: 0.7646 - mse: 0.3328 - mace: 24.4658 - val_loss: 0.7690 - val_mse: 0.3364 - val_mace: 24.6065

Epoch 00033: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 33/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7651 - mse: 0.3333 - mace: 24.4837  
Epoch 00033: val_loss did not improve from 0.75985
2033/2033 [==============================] - 110s 54ms/step - loss: 0.7651 - mse: 0.3333 - mace: 24.4830 - val_loss: 0.7672 - val_mse: 0.3347 - val_mace: 24.5506

Epoch 00034: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 34/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7669 - mse: 0.3346 - mace: 24.5400  
Epoch 00034: val_loss did not improve from 0.75985
2033/2033 [==============================] - 134s 66ms/step - loss: 0.7669 - mse: 0.3346 - mace: 24.5403 - val_loss: 0.7602 - val_mse: 0.3294 - val_mace: 24.3260

Epoch 00035: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 35/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7661 - mse: 0.3340 - mace: 24.5144  
Epoch 00035: val_loss did not improve from 0.75985
2033/2033 [==============================] - 121s 59ms/step - loss: 0.7661 - mse: 0.3340 - mace: 24.5150 - val_loss: 0.7631 - val_mse: 0.3313 - val_mace: 24.4181

Epoch 00036: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 36/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3331 - mace: 24.4697  
Epoch 00036: val_loss did not improve from 0.75985
2033/2033 [==============================] - 115s 57ms/step - loss: 0.7647 - mse: 0.3331 - mace: 24.4693 - val_loss: 0.7667 - val_mse: 0.3349 - val_mace: 24.5359

Epoch 00037: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 37/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7686 - mse: 0.6385 - mace: 24.5950  
Epoch 00037: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 58ms/step - loss: 0.7686 - mse: 0.6384 - mace: 24.5953 - val_loss: 0.7636 - val_mse: 0.3321 - val_mace: 24.4344

Epoch 00038: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 38/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7652 - mse: 0.3334 - mace: 24.4877  
Epoch 00038: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7652 - mse: 0.3334 - mace: 24.4880 - val_loss: 0.7628 - val_mse: 0.3313 - val_mace: 24.4096

Epoch 00039: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 39/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7648 - mse: 0.3331 - mace: 24.4751  
Epoch 00039: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7648 - mse: 0.3331 - mace: 24.4752 - val_loss: 0.7652 - val_mse: 0.3334 - val_mace: 24.4871

Epoch 00040: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 40/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7653 - mse: 0.3334 - mace: 24.4883  
Epoch 00040: val_loss did not improve from 0.75985
2033/2033 [==============================] - 115s 56ms/step - loss: 0.7653 - mse: 0.3334 - mace: 24.4880 - val_loss: 0.7671 - val_mse: 0.3346 - val_mace: 24.5460

Epoch 00041: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 41/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7651 - mse: 0.3332 - mace: 24.4826   
Epoch 00041: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7651 - mse: 0.3332 - mace: 24.4832 - val_loss: 0.7650 - val_mse: 0.3331 - val_mace: 24.4801

Epoch 00042: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 42/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7668 - mse: 0.3345 - mace: 24.5373  
Epoch 00042: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7668 - mse: 0.3345 - mace: 24.5372 - val_loss: 0.7652 - val_mse: 0.3335 - val_mace: 24.4850

Epoch 00043: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 43/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7637 - mse: 0.3324 - mace: 24.4398  
Epoch 00043: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7637 - mse: 0.3323 - mace: 24.4388 - val_loss: 0.7645 - val_mse: 0.3328 - val_mace: 24.4635

Epoch 00044: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 44/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7666 - mse: 0.3341 - mace: 24.5300  
Epoch 00044: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7666 - mse: 0.3342 - mace: 24.5310 - val_loss: 0.7627 - val_mse: 0.3315 - val_mace: 24.4049

Epoch 00045: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 45/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3331 - mace: 24.4718   
Epoch 00045: val_loss did not improve from 0.75985
2033/2033 [==============================] - 125s 62ms/step - loss: 0.7647 - mse: 0.3331 - mace: 24.4714 - val_loss: 0.7603 - val_mse: 0.3296 - val_mace: 24.3298

Epoch 00046: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 46/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7648 - mse: 0.3332 - mace: 24.4748  
Epoch 00046: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7649 - mse: 0.3332 - mace: 24.4756 - val_loss: 0.7644 - val_mse: 0.3326 - val_mace: 24.4613

Epoch 00047: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 47/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7659 - mse: 0.3338 - mace: 24.5076  
Epoch 00047: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7658 - mse: 0.3337 - mace: 24.5064 - val_loss: 0.7669 - val_mse: 0.3347 - val_mace: 24.5406

Epoch 00048: LearningRateScheduler reducing learning rate to 0.0004999999655410647.
Epoch 48/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7658 - mse: 0.3339 - mace: 24.5064  
Epoch 00048: val_loss did not improve from 0.75985
2033/2033 [==============================] - 126s 62ms/step - loss: 0.7658 - mse: 0.3339 - mace: 24.5065 - val_loss: 0.7680 - val_mse: 0.3355 - val_mace: 24.5760

Epoch 00049: LearningRateScheduler reducing learning rate to 4.9999996554106475e-05.
Epoch 49/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7637 - mse: 0.3324 - mace: 24.4378  
Epoch 00049: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7637 - mse: 0.3324 - mace: 24.4384 - val_loss: 0.7647 - val_mse: 0.3327 - val_mace: 24.4688

Epoch 00050: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 50/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7653 - mse: 0.3378 - mace: 24.4901  
Epoch 00050: val_loss did not improve from 0.75985
2033/2033 [==============================] - 110s 54ms/step - loss: 0.7653 - mse: 0.3378 - mace: 24.4891 - val_loss: 0.7639 - val_mse: 0.3320 - val_mace: 24.4459

Epoch 00051: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 51/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7659 - mse: 0.3337 - mace: 24.5082   
Epoch 00051: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7659 - mse: 0.3337 - mace: 24.5078 - val_loss: 0.7641 - val_mse: 0.3326 - val_mace: 24.4512

Epoch 00052: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 52/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7643 - mse: 0.3327 - mace: 24.4583  
Epoch 00052: val_loss did not improve from 0.75985
2033/2033 [==============================] - 112s 55ms/step - loss: 0.7643 - mse: 0.3327 - mace: 24.4579 - val_loss: 0.7645 - val_mse: 0.3330 - val_mace: 24.4643

Epoch 00053: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 53/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7652 - mse: 0.3332 - mace: 24.4873  
Epoch 00053: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7652 - mse: 0.3332 - mace: 24.4863 - val_loss: 0.7662 - val_mse: 0.3340 - val_mace: 24.5190

Epoch 00054: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 54/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7661 - mse: 0.3340 - mace: 24.5141  
Epoch 00054: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7661 - mse: 0.3340 - mace: 24.5140 - val_loss: 0.7642 - val_mse: 0.3326 - val_mace: 24.4543

Epoch 00055: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 55/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7648 - mse: 0.3331 - mace: 24.4738   
Epoch 00055: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7648 - mse: 0.3331 - mace: 24.4737 - val_loss: 0.7609 - val_mse: 0.3296 - val_mace: 24.3485

Epoch 00056: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 56/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7640 - mse: 0.3328 - mace: 24.4492  
Epoch 00056: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7641 - mse: 0.3328 - mace: 24.4501 - val_loss: 0.7683 - val_mse: 0.3360 - val_mace: 24.5864

Epoch 00057: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 57/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7664 - mse: 0.3342 - mace: 24.5257  
Epoch 00057: val_loss did not improve from 0.75985
2033/2033 [==============================] - 121s 59ms/step - loss: 0.7664 - mse: 0.3342 - mace: 24.5258 - val_loss: 0.7671 - val_mse: 0.3346 - val_mace: 24.5459

Epoch 00058: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 58/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7648 - mse: 0.3331 - mace: 24.4725  
Epoch 00058: val_loss did not improve from 0.75985
2033/2033 [==============================] - 121s 60ms/step - loss: 0.7648 - mse: 0.3331 - mace: 24.4723 - val_loss: 0.7654 - val_mse: 0.3335 - val_mace: 24.4913

Epoch 00059: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 59/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3330 - mace: 24.4719   
Epoch 00059: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7647 - mse: 0.3330 - mace: 24.4711 - val_loss: 0.7628 - val_mse: 0.3315 - val_mace: 24.4092

Epoch 00060: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 60/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7661 - mse: 0.3341 - mace: 24.5149  
Epoch 00060: val_loss did not improve from 0.75985
2033/2033 [==============================] - 112s 55ms/step - loss: 0.7661 - mse: 0.3341 - mace: 24.5145 - val_loss: 0.7639 - val_mse: 0.3323 - val_mace: 24.4453

Epoch 00061: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 61/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7656 - mse: 0.3336 - mace: 24.5002   
Epoch 00061: val_loss did not improve from 0.75985
2033/2033 [==============================] - 129s 63ms/step - loss: 0.7656 - mse: 0.3336 - mace: 24.5003 - val_loss: 0.7650 - val_mse: 0.3332 - val_mace: 24.4803

Epoch 00062: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 62/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7649 - mse: 0.3332 - mace: 24.4775  
Epoch 00062: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7649 - mse: 0.3332 - mace: 24.4779 - val_loss: 0.7648 - val_mse: 0.3330 - val_mace: 24.4733

Epoch 00063: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 63/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7660 - mse: 0.3339 - mace: 24.5134  
Epoch 00063: val_loss did not improve from 0.75985
2033/2033 [==============================] - 122s 60ms/step - loss: 0.7660 - mse: 0.3339 - mace: 24.5126 - val_loss: 0.7649 - val_mse: 0.3331 - val_mace: 24.4758

Epoch 00064: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 64/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7642 - mse: 0.3327 - mace: 24.4557  
Epoch 00064: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7643 - mse: 0.3327 - mace: 24.4568 - val_loss: 0.7683 - val_mse: 0.3359 - val_mace: 24.5857

Epoch 00065: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 65/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7666 - mse: 0.3596 - mace: 24.5316   
Epoch 00065: val_loss did not improve from 0.75985
2033/2033 [==============================] - 122s 60ms/step - loss: 0.7666 - mse: 0.3596 - mace: 24.5322 - val_loss: 0.7669 - val_mse: 0.3343 - val_mace: 24.5409

Epoch 00066: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 66/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3331 - mace: 24.4689  
Epoch 00066: val_loss did not improve from 0.75985
2033/2033 [==============================] - 112s 55ms/step - loss: 0.7647 - mse: 0.3331 - mace: 24.4689 - val_loss: 0.7599 - val_mse: 0.3293 - val_mace: 24.3173

Epoch 00067: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 67/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7648 - mse: 0.3333 - mace: 24.4747  
Epoch 00067: val_loss did not improve from 0.75985
2033/2033 [==============================] - 126s 62ms/step - loss: 0.7648 - mse: 0.3333 - mace: 24.4752 - val_loss: 0.7668 - val_mse: 0.3347 - val_mace: 24.5365

Epoch 00068: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 68/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7656 - mse: 0.3337 - mace: 24.5000  
Epoch 00068: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 58ms/step - loss: 0.7657 - mse: 0.3337 - mace: 24.5008 - val_loss: 0.7625 - val_mse: 0.3311 - val_mace: 24.4013

Epoch 00069: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 69/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7655 - mse: 0.3336 - mace: 24.4945  
Epoch 00069: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7654 - mse: 0.3336 - mace: 24.4935 - val_loss: 0.7642 - val_mse: 0.3328 - val_mace: 24.4542

Epoch 00070: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 70/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7654 - mse: 0.3336 - mace: 24.4915  
Epoch 00070: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7654 - mse: 0.3336 - mace: 24.4920 - val_loss: 0.7632 - val_mse: 0.3316 - val_mace: 24.4220

Epoch 00071: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 71/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7660 - mse: 0.3508 - mace: 24.5135  
Epoch 00071: val_loss did not improve from 0.75985
2033/2033 [==============================] - 113s 56ms/step - loss: 0.7661 - mse: 0.3508 - mace: 24.5140 - val_loss: 0.7607 - val_mse: 0.3294 - val_mace: 24.3418

Epoch 00072: LearningRateScheduler reducing learning rate to 4.999999509891495e-05.
Epoch 72/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7649 - mse: 0.3332 - mace: 24.4765  
Epoch 00072: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7649 - mse: 0.3332 - mace: 24.4762 - val_loss: 0.7698 - val_mse: 0.3371 - val_mace: 24.6331

Epoch 00073: LearningRateScheduler reducing learning rate to 4.999999509891496e-06.
Epoch 73/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7662 - mse: 0.3340 - mace: 24.5188  
Epoch 00073: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 58ms/step - loss: 0.7662 - mse: 0.3340 - mace: 24.5185 - val_loss: 0.7648 - val_mse: 0.3328 - val_mace: 24.4731

Epoch 00074: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 74/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7667 - mse: 0.3345 - mace: 24.5345  
Epoch 00074: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 57ms/step - loss: 0.7667 - mse: 0.3345 - mace: 24.5354 - val_loss: 0.7650 - val_mse: 0.3335 - val_mace: 24.4802

Epoch 00075: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 75/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7657 - mse: 0.3336 - mace: 24.5040   
Epoch 00075: val_loss did not improve from 0.75985
2033/2033 [==============================] - 127s 62ms/step - loss: 0.7658 - mse: 0.3336 - mace: 24.5049 - val_loss: 0.7647 - val_mse: 0.3329 - val_mace: 24.4698

Epoch 00076: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 76/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7659 - mse: 0.3340 - mace: 24.5099  
Epoch 00076: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7659 - mse: 0.3340 - mace: 24.5100 - val_loss: 0.7648 - val_mse: 0.3330 - val_mace: 24.4730

Epoch 00077: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 77/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7634 - mse: 0.3323 - mace: 24.4301  
Epoch 00077: val_loss did not improve from 0.75985
2033/2033 [==============================] - 114s 56ms/step - loss: 0.7634 - mse: 0.3322 - mace: 24.4294 - val_loss: 0.7671 - val_mse: 0.3346 - val_mace: 24.5484

Epoch 00078: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 78/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3331 - mace: 24.4695  
Epoch 00078: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7647 - mse: 0.3332 - mace: 24.4703 - val_loss: 0.7635 - val_mse: 0.3319 - val_mace: 24.4309

Epoch 00079: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 79/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7652 - mse: 0.3334 - mace: 24.4875  
Epoch 00079: val_loss did not improve from 0.75985
2033/2033 [==============================] - 125s 61ms/step - loss: 0.7652 - mse: 0.3334 - mace: 24.4876 - val_loss: 0.7679 - val_mse: 0.3356 - val_mace: 24.5716

Epoch 00080: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 80/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7640 - mse: 0.3325 - mace: 24.4493  
Epoch 00080: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7640 - mse: 0.3324 - mace: 24.4475 - val_loss: 0.7644 - val_mse: 0.3330 - val_mace: 24.4616

Epoch 00081: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 81/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7659 - mse: 0.3338 - mace: 24.5102  
Epoch 00081: val_loss did not improve from 0.75985
2033/2033 [==============================] - 121s 59ms/step - loss: 0.7659 - mse: 0.3338 - mace: 24.5101 - val_loss: 0.7614 - val_mse: 0.3300 - val_mace: 24.3654

Epoch 00082: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 82/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7653 - mse: 0.3335 - mace: 24.4886  
Epoch 00082: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7653 - mse: 0.3335 - mace: 24.4886 - val_loss: 0.7637 - val_mse: 0.3319 - val_mace: 24.4396

Epoch 00083: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 83/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7651 - mse: 0.3333 - mace: 24.4835  
Epoch 00083: val_loss did not improve from 0.75985
2033/2033 [==============================] - 124s 61ms/step - loss: 0.7651 - mse: 0.3333 - mace: 24.4839 - val_loss: 0.7623 - val_mse: 0.3312 - val_mace: 24.3935

Epoch 00084: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 84/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.3329 - mace: 24.4704  
Epoch 00084: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 57ms/step - loss: 0.7647 - mse: 0.3329 - mace: 24.4708 - val_loss: 0.7653 - val_mse: 0.3335 - val_mace: 24.4884

Epoch 00085: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 85/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7650 - mse: 0.3330 - mace: 24.4791  
Epoch 00085: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7650 - mse: 0.3330 - mace: 24.4795 - val_loss: 0.7662 - val_mse: 0.3340 - val_mace: 24.5170

Epoch 00086: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 86/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7660 - mse: 0.3340 - mace: 24.5115  
Epoch 00086: val_loss did not improve from 0.75985
2033/2033 [==============================] - 117s 57ms/step - loss: 0.7660 - mse: 0.3340 - mace: 24.5118 - val_loss: 0.7644 - val_mse: 0.3327 - val_mace: 24.4604

Epoch 00087: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 87/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7656 - mse: 0.3336 - mace: 24.4997  
Epoch 00087: val_loss did not improve from 0.75985
2033/2033 [==============================] - 116s 57ms/step - loss: 0.7656 - mse: 0.3336 - mace: 24.4997 - val_loss: 0.7664 - val_mse: 0.3343 - val_mace: 24.5249

Epoch 00088: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 88/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7652 - mse: 0.3334 - mace: 24.4855  
Epoch 00088: val_loss did not improve from 0.75985
2033/2033 [==============================] - 121s 60ms/step - loss: 0.7651 - mse: 0.3333 - mace: 24.4844 - val_loss: 0.7653 - val_mse: 0.3335 - val_mace: 24.4906

Epoch 00089: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 89/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7640 - mse: 0.3328 - mace: 24.4495  
Epoch 00089: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7640 - mse: 0.3328 - mace: 24.4491 - val_loss: 0.7671 - val_mse: 0.3353 - val_mace: 24.5474

Epoch 00090: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 90/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7654 - mse: 0.3335 - mace: 24.4916  
Epoch 00090: val_loss did not improve from 0.75985
2033/2033 [==============================] - 120s 59ms/step - loss: 0.7654 - mse: 0.3335 - mace: 24.4924 - val_loss: 0.7656 - val_mse: 0.3335 - val_mace: 24.4987

Epoch 00091: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 91/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7658 - mse: 0.3338 - mace: 24.5053  
Epoch 00091: val_loss did not improve from 0.75985
2033/2033 [==============================] - 128s 63ms/step - loss: 0.7658 - mse: 0.3338 - mace: 24.5052 - val_loss: 0.7678 - val_mse: 0.3354 - val_mace: 24.5708

Epoch 00092: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 92/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7658 - mse: 0.3338 - mace: 24.5069  
Epoch 00092: val_loss did not improve from 0.75985
2033/2033 [==============================] - 108s 53ms/step - loss: 0.7659 - mse: 0.3338 - mace: 24.5073 - val_loss: 0.7646 - val_mse: 0.3327 - val_mace: 24.4662

Epoch 00093: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 93/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7652 - mse: 0.3333 - mace: 24.4866  
Epoch 00093: val_loss did not improve from 0.75985
2033/2033 [==============================] - 110s 54ms/step - loss: 0.7652 - mse: 0.3333 - mace: 24.4860 - val_loss: 0.7652 - val_mse: 0.3334 - val_mace: 24.4871

Epoch 00094: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 94/98
2031/2033 [============================>.] - ETA: 0s - loss: 0.7664 - mse: 0.3343 - mace: 24.5241  
Epoch 00094: val_loss did not improve from 0.75985
2033/2033 [==============================] - 118s 58ms/step - loss: 0.7664 - mse: 0.3343 - mace: 24.5241 - val_loss: 0.7636 - val_mse: 0.3322 - val_mace: 24.4361

Epoch 00095: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 95/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7658 - mse: 0.3337 - mace: 24.5050  
Epoch 00095: val_loss did not improve from 0.75985
2033/2033 [==============================] - 123s 61ms/step - loss: 0.7658 - mse: 0.3337 - mace: 24.5065 - val_loss: 0.7650 - val_mse: 0.3333 - val_mace: 24.4803

Epoch 00096: LearningRateScheduler reducing learning rate to 4.999999418942025e-06.
Epoch 96/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7632 - mse: 0.3320 - mace: 24.4209  
Epoch 00096: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 59ms/step - loss: 0.7631 - mse: 0.3320 - mace: 24.4201 - val_loss: 0.7642 - val_mse: 0.3326 - val_mace: 24.4550

Epoch 00097: LearningRateScheduler reducing learning rate to 4.999999418942025e-07.
Epoch 97/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7653 - mse: 0.3333 - mace: 24.4905  
Epoch 00097: val_loss did not improve from 0.75985
2033/2033 [==============================] - 119s 58ms/step - loss: 0.7653 - mse: 0.3333 - mace: 24.4903 - val_loss: 0.7617 - val_mse: 0.3302 - val_mace: 24.3757

Epoch 00098: LearningRateScheduler reducing learning rate to 4.999999418942025e-07.
Epoch 98/98
2032/2033 [============================>.] - ETA: 0s - loss: 0.7655 - mse: 0.3337 - mace: 24.4949  
Epoch 00098: val_loss did not improve from 0.75985
2033/2033 [==============================] - 111s 55ms/step - loss: 0.7655 - mse: 0.3337 - mace: 24.4966 - val_loss: 0.7630 - val_mse: 0.3314 - val_mace: 24.4156
